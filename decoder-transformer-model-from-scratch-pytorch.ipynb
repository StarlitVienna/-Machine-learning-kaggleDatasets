{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/evelynartoria/decoder-transformer-model-from-scratch-pytorch?scriptVersionId=187731215\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"00cd8e78","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:20.973884Z","iopub.status.busy":"2024-07-11T00:04:20.973215Z","iopub.status.idle":"2024-07-11T00:04:21.99213Z","shell.execute_reply":"2024-07-11T00:04:21.990997Z"},"papermill":{"duration":1.030655,"end_time":"2024-07-11T00:04:21.994696","exception":false,"start_time":"2024-07-11T00:04:20.964041","status":"completed"},"tags":[]},"outputs":[],"source":["!mkdir ./models"]},{"cell_type":"code","execution_count":2,"id":"1af10a32","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:22.011165Z","iopub.status.busy":"2024-07-11T00:04:22.010848Z","iopub.status.idle":"2024-07-11T00:04:25.317829Z","shell.execute_reply":"2024-07-11T00:04:25.31693Z"},"papermill":{"duration":3.317773,"end_time":"2024-07-11T00:04:25.320097","exception":false,"start_time":"2024-07-11T00:04:22.002324","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":3,"id":"bed031f1","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:25.336333Z","iopub.status.busy":"2024-07-11T00:04:25.335945Z","iopub.status.idle":"2024-07-11T00:04:25.419757Z","shell.execute_reply":"2024-07-11T00:04:25.418696Z"},"papermill":{"duration":0.09429,"end_time":"2024-07-11T00:04:25.421958","exception":false,"start_time":"2024-07-11T00:04:25.327668","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["default device set to cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","generator = torch.Generator(device=device)\n","torch.set_default_device(device)\n","print(f\"default device set to {device}\")"]},{"cell_type":"code","execution_count":4,"id":"ab59d675","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:25.438579Z","iopub.status.busy":"2024-07-11T00:04:25.43827Z","iopub.status.idle":"2024-07-11T00:04:25.462243Z","shell.execute_reply":"2024-07-11T00:04:25.461185Z"},"papermill":{"duration":0.034947,"end_time":"2024-07-11T00:04:25.464813","exception":false,"start_time":"2024-07-11T00:04:25.429866","status":"completed"},"tags":[]},"outputs":[],"source":["with open(\"/kaggle/input/shakespeare/input.txt\", 'r', encoding=\"utf-8\") as f:\n","    text = f.read()"]},{"cell_type":"code","execution_count":5,"id":"82945e8a","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:25.484526Z","iopub.status.busy":"2024-07-11T00:04:25.483638Z","iopub.status.idle":"2024-07-11T00:04:25.509834Z","shell.execute_reply":"2024-07-11T00:04:25.508613Z"},"papermill":{"duration":0.037702,"end_time":"2024-07-11T00:04:25.512244","exception":false,"start_time":"2024-07-11T00:04:25.474542","status":"completed"},"tags":[]},"outputs":[],"source":["vocab = sorted(set(text))\n","vocab_size = len(vocab)"]},{"cell_type":"code","execution_count":6,"id":"e5d3b055","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:25.533087Z","iopub.status.busy":"2024-07-11T00:04:25.532681Z","iopub.status.idle":"2024-07-11T00:04:25.540153Z","shell.execute_reply":"2024-07-11T00:04:25.5388Z"},"papermill":{"duration":0.021762,"end_time":"2024-07-11T00:04:25.54301","exception":false,"start_time":"2024-07-11T00:04:25.521248","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["46\n","h\n"]}],"source":["stoi = {c: v for v, c in enumerate(vocab)}\n","itos = {v: c for c, v in stoi.items()}\n","\n","print(stoi[\"h\"])\n","print(itos[46])"]},{"cell_type":"code","execution_count":7,"id":"daff1613","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:25.565066Z","iopub.status.busy":"2024-07-11T00:04:25.564654Z","iopub.status.idle":"2024-07-11T00:04:25.570805Z","shell.execute_reply":"2024-07-11T00:04:25.56996Z"},"papermill":{"duration":0.01974,"end_time":"2024-07-11T00:04:25.572864","exception":false,"start_time":"2024-07-11T00:04:25.553124","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[46, 43, 50, 50, 53, 1, 46, 53, 61, 1, 39, 56, 43, 1, 63, 53, 59, 12] hello how are you?\n"]}],"source":["encode = lambda e: [stoi[ch] for ch in e]\n","decode = lambda d: \"\".join([itos[idx] for idx in d])\n","\n","encoded = encode(\"hello how are you?\")\n","decoded = decode(encoded)\n","\n","print(encoded, decoded)"]},{"cell_type":"code","execution_count":8,"id":"54eaa026","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:25.589645Z","iopub.status.busy":"2024-07-11T00:04:25.589015Z","iopub.status.idle":"2024-07-11T00:04:25.91682Z","shell.execute_reply":"2024-07-11T00:04:25.91555Z"},"papermill":{"duration":0.338293,"end_time":"2024-07-11T00:04:25.918779","exception":false,"start_time":"2024-07-11T00:04:25.580486","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([9344, 2176, 1024, 1280, 9088,    0, 7296, 5888, 2048, 6528, 2688, 4224,\n","        9728, 1152, 4096, 5504, 3712, 5248,  640, 6016, 4992, 1920, 6272, 2816,\n","        9600, 2304, 3328, 2944, 3968,  256, 1664, 6656, 7424, 8192, 6400, 7808,\n","        7680, 3200,  128,  768, 4352, 1408, 8448, 4480, 1792, 8704, 7552, 8064,\n","        7040,  896, 1536, 9856, 6144, 4608,  384, 7168, 3072, 5120, 8960, 3840,\n","        3456, 8576, 4736, 5376, 5632, 4864, 2560, 7936, 8832, 3584, 8320, 2432,\n","        9472, 9216, 5760, 6784, 6912,  512], device='cuda:0')\n"]}],"source":["context_size = 128\n","random_idx_tensor = torch.randperm(10000//context_size) * context_size\n","print(random_idx_tensor)"]},{"cell_type":"code","execution_count":9,"id":"3f41b49e","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:25.936778Z","iopub.status.busy":"2024-07-11T00:04:25.936474Z","iopub.status.idle":"2024-07-11T00:04:25.942708Z","shell.execute_reply":"2024-07-11T00:04:25.941721Z"},"papermill":{"duration":0.017997,"end_time":"2024-07-11T00:04:25.944798","exception":false,"start_time":"2024-07-11T00:04:25.926801","status":"completed"},"tags":[]},"outputs":[],"source":["def make_dataset(data):\n","    random_idx_tensor = torch.randperm((len(data)-context_size)//context_size) * context_size\n","    inputs = torch.stack([data[idx:idx+context_size] for idx in random_idx_tensor])\n","    labels = torch.stack([data[idx+1:idx+context_size+1] for idx in random_idx_tensor])\n","    \n","    return TensorDataset(inputs.to(torch.long), labels.to(torch.long))"]},{"cell_type":"code","execution_count":10,"id":"2a6e5eaa","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:25.962212Z","iopub.status.busy":"2024-07-11T00:04:25.961941Z","iopub.status.idle":"2024-07-11T00:04:27.842637Z","shell.execute_reply":"2024-07-11T00:04:27.841419Z"},"papermill":{"duration":1.892007,"end_time":"2024-07-11T00:04:27.845075","exception":false,"start_time":"2024-07-11T00:04:25.953068","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 1, 21,  1, 58, 53, 50, 42,  1, 63, 53, 59,  1, 53, 44, 10,  0, 21,  1,\n","        54, 56, 39, 63,  1, 63, 53, 59,  1, 57, 58, 39, 52, 42,  1, 45, 53, 53,\n","        42,  1, 44, 39, 58, 46, 43, 56,  1, 58, 53,  1, 51, 43,  1, 52, 53, 61,\n","         6,  0, 19, 47, 60, 43,  1, 51, 43,  1, 14, 47, 39, 52, 41, 39,  1, 44,\n","        53, 56,  1, 51, 63,  1, 54, 39, 58, 56, 47, 51, 53, 52, 63,  8,  0,  0,\n","        28, 43, 42, 39, 52, 58, 10,  0, 31, 53, 44, 58,  1, 57, 53, 52,  2,  0,\n","        31, 47, 56,  6,  1, 40, 63,  1, 63, 53, 59, 56,  1, 50, 43, 39, 60, 43,\n","        10,  1], device='cuda:0')\n","tensor([21,  1, 58, 53, 50, 42,  1, 63, 53, 59,  1, 53, 44, 10,  0, 21,  1, 54,\n","        56, 39, 63,  1, 63, 53, 59,  1, 57, 58, 39, 52, 42,  1, 45, 53, 53, 42,\n","         1, 44, 39, 58, 46, 43, 56,  1, 58, 53,  1, 51, 43,  1, 52, 53, 61,  6,\n","         0, 19, 47, 60, 43,  1, 51, 43,  1, 14, 47, 39, 52, 41, 39,  1, 44, 53,\n","        56,  1, 51, 63,  1, 54, 39, 58, 56, 47, 51, 53, 52, 63,  8,  0,  0, 28,\n","        43, 42, 39, 52, 58, 10,  0, 31, 53, 44, 58,  1, 57, 53, 52,  2,  0, 31,\n","        47, 56,  6,  1, 40, 63,  1, 63, 53, 59, 56,  1, 50, 43, 39, 60, 43, 10,\n","         1, 46], device='cuda:0')\n","dataset length --> 8713 (1115264 characters), that is, about the length of text 1115394 - context_size --> 1115266\n"]}],"source":["data = torch.tensor(encode(text))\n","dataset = make_dataset(data=data)\n","sample_input = dataset[0][0]\n","sample_label = dataset[0][1]\n","\n","print(sample_input)\n","print(sample_label)\n","\n","print(f\"dataset length --> {len(dataset)} ({len(dataset) * context_size} characters), that is, about the length of text {len(text)} - context_size --> {len(text)-context_size}\")"]},{"cell_type":"code","execution_count":11,"id":"3411701c","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:27.86306Z","iopub.status.busy":"2024-07-11T00:04:27.862334Z","iopub.status.idle":"2024-07-11T00:04:27.868895Z","shell.execute_reply":"2024-07-11T00:04:27.868188Z"},"papermill":{"duration":0.017499,"end_time":"2024-07-11T00:04:27.870818","exception":false,"start_time":"2024-07-11T00:04:27.853319","status":"completed"},"tags":[]},"outputs":[],"source":["train_split = int(len(dataset)*0.75)\n","test_split = int(len(dataset)-train_split)\n","\n","train_dataset, test_dataset = random_split(dataset=dataset, lengths=[train_split, test_split], generator=generator)"]},{"cell_type":"code","execution_count":12,"id":"788ccaf4","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:27.88791Z","iopub.status.busy":"2024-07-11T00:04:27.887648Z","iopub.status.idle":"2024-07-11T00:04:27.892569Z","shell.execute_reply":"2024-07-11T00:04:27.891619Z"},"papermill":{"duration":0.015642,"end_time":"2024-07-11T00:04:27.894511","exception":false,"start_time":"2024-07-11T00:04:27.878869","status":"completed"},"tags":[]},"outputs":[],"source":["batch_size = 32\n","train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, generator=generator)\n","test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, generator=generator)"]},{"cell_type":"code","execution_count":13,"id":"8dd415b4","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:27.911134Z","iopub.status.busy":"2024-07-11T00:04:27.91085Z","iopub.status.idle":"2024-07-11T00:04:27.919664Z","shell.execute_reply":"2024-07-11T00:04:27.918937Z"},"papermill":{"duration":0.019623,"end_time":"2024-07-11T00:04:27.921711","exception":false,"start_time":"2024-07-11T00:04:27.902088","status":"completed"},"tags":[]},"outputs":[],"source":["class Head(nn.Module):\n","    def __init__(self, n_embd, head_size, context_size):\n","        super(Head, self).__init__()\n","        \n","        self.Q = nn.Linear(in_features=n_embd, out_features=head_size) # takes in BxTxC and return BxTxHead_size\n","        self.K = nn.Linear(in_features=n_embd, out_features=head_size)\n","        self.V = nn.Linear(in_features=n_embd, out_features=head_size)\n","        \n","        self.register_buffer(\"tril\", torch.tril(torch.ones(size=(context_size, context_size))))\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        B, T, C = x.shape # batch_size by context_size by n_embd\n","        q = self.Q(x) # BxTxHead_size\n","        k = self.K(x) # BxTxHead_size\n","        \n","        wei = q @ k.transpose(-2, -1) * (C ** -0.5) # BxTxHead_size @ BxHead_sizexT --> BxTxT then divided by the square root of n_embd\n","        \n","        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # :T and :T is needed in case context is smaller than context_size\n","        wei = torch.softmax(wei, dim=-1)\n","        v = self.V(x) # BxTxHead_size\n","        output = wei @ v # BxTxT @ BxTxHead_size --> BxTxHead_size\n","        \n","        return output"]},{"cell_type":"code","execution_count":14,"id":"a498efde","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:27.938233Z","iopub.status.busy":"2024-07-11T00:04:27.937953Z","iopub.status.idle":"2024-07-11T00:04:27.944772Z","shell.execute_reply":"2024-07-11T00:04:27.943797Z"},"papermill":{"duration":0.017421,"end_time":"2024-07-11T00:04:27.946739","exception":false,"start_time":"2024-07-11T00:04:27.929318","status":"completed"},"tags":[]},"outputs":[],"source":["class MultiHeadedAttention(nn.Module):\n","    def __init__(self, n_embd, context_size, n_heads, head_size):\n","        super(MultiHeadedAttention, self).__init__()\n","        self.heads = nn.ModuleList([Head(n_embd=n_embd, head_size=head_size, context_size=context_size) for _ in range(n_heads)]) # BxTx (n_heads * head_size)\n","        self.projection = nn.Linear(in_features=n_heads*head_size, out_features=n_embd) # ensures the output is going to be o shape BxTxn_embd (BxTxC) so that is can go through multiple attention block\n","        \n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = torch.cat([head(x) for head in self.heads], dim=-1) # cat in the Channels dimension; output shape is BxTx (n_heads * head_size)\n","        x = self.projection(x)\n","        return  x"]},{"cell_type":"code","execution_count":15,"id":"6302ad35","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:27.963824Z","iopub.status.busy":"2024-07-11T00:04:27.963126Z","iopub.status.idle":"2024-07-11T00:04:27.969384Z","shell.execute_reply":"2024-07-11T00:04:27.968445Z"},"papermill":{"duration":0.017034,"end_time":"2024-07-11T00:04:27.97144","exception":false,"start_time":"2024-07-11T00:04:27.954406","status":"completed"},"tags":[]},"outputs":[],"source":["class FeedForward(nn.Module):\n","    def __init__(self, in_features):\n","        super(FeedForward, self).__init__()\n","        self.ffwrd_layer = nn.Sequential(\n","            nn.Linear(in_features=in_features, out_features=in_features * 4), # scale by 4, according to the attention is all you need paper\n","            nn.ReLU(),\n","            nn.Linear(in_features=in_features * 4, out_features=in_features) # another projection layer\n","        )\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        return self.ffwrd_layer(x)"]},{"cell_type":"code","execution_count":16,"id":"6034488e","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:27.988243Z","iopub.status.busy":"2024-07-11T00:04:27.987986Z","iopub.status.idle":"2024-07-11T00:04:27.994307Z","shell.execute_reply":"2024-07-11T00:04:27.993465Z"},"papermill":{"duration":0.016685,"end_time":"2024-07-11T00:04:27.996211","exception":false,"start_time":"2024-07-11T00:04:27.979526","status":"completed"},"tags":[]},"outputs":[],"source":["class Block(nn.Module):\n","    def __init__(self, n_heads, head_size, n_embd, context_size):\n","        super(Block, self).__init__()\n","        self.multiheaded_self_attetion = MultiHeadedAttention(n_embd=n_embd, context_size=context_size, n_heads=n_heads, head_size=head_size) # create a multiheaded attention block; returns shape BxTx (num_heads*head_size)\n","        self.ffwrd = FeedForward(in_features=n_embd)\n","        self.layer_norm1 = nn.LayerNorm(n_embd)\n","        self.layer_norm2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = x + self.multiheaded_self_attetion(self.layer_norm1(x))\n","        x = x + self.ffwrd(self.layer_norm2(x))\n","\n","        return x"]},{"cell_type":"code","execution_count":17,"id":"5cd30325","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:28.013522Z","iopub.status.busy":"2024-07-11T00:04:28.013224Z","iopub.status.idle":"2024-07-11T00:04:28.026186Z","shell.execute_reply":"2024-07-11T00:04:28.025296Z"},"papermill":{"duration":0.024046,"end_time":"2024-07-11T00:04:28.02814","exception":false,"start_time":"2024-07-11T00:04:28.004094","status":"completed"},"tags":[]},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, n_embd, context_size, vocab_size, num_sa_heads, sa_head_size):\n","        super().__init__()\n","        \n","        self.vocab_size = vocab_size\n","        self.context_size = context_size\n","        self.n_embd = n_embd\n","        \n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # each character from the vocab has n_embd values associated to it\n","        self.positional_embedding_table = nn.Embedding(context_size, n_embd) # each character position in the context has n_embd values associated to it\n","        \n","        self.attention_blocks = nn.Sequential(\n","            Block(n_heads=num_sa_heads, head_size=sa_head_size, context_size=self.context_size, n_embd=self.n_embd), # takes in BxTxC, calculate logits of BxTx (num_heads * head_size), then project it as BxTxC\n","            Block(n_heads=num_sa_heads, head_size=sa_head_size, context_size=self.context_size, n_embd=self.n_embd),\n","            Block(n_heads=num_sa_heads, head_size=sa_head_size, context_size=self.context_size, n_embd=self.n_embd),\n","            nn.LayerNorm(n_embd) # normalize the layers\n","        )\n","        \n","\n","        self.lm_head = nn.Linear(in_features=n_embd, out_features=vocab_size) # (B, T, vocab_size)\n","        \n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        B, T = x.shape # batch_size and context_size\n","        positions = torch.arange(start=0, end=T, step=1)\n","        \n","        pos_emb = self.positional_embedding_table(positions) # T x C --> in broadcasting, pytorch adds a batch dim=1\n","        token_emb = self.token_embedding_table(x) # B x T x C\n","        \n","        x = token_emb + pos_emb # BxTxC\n","        x = self.attention_blocks(x) # returns logits of shape BxTx (self.sa_head_size * self.num_sa_heads) projected to BxTxC\n","        x = self.lm_head(x) # BxTxvocab_size --> BxTxHead_size @ BxTxVocab_size return BxTxVocab_size\n","\n","        return x.view(B*T, self.vocab_size) # easier shape to work with the labels\n","    \n","    def generate(self, starting_idx: torch.Tensor, max_length: int, debug: bool) -> torch.Tensor:\n","        full_text = decode([starting_idx.item()])\n","        context = starting_idx\n","        \n","        for _ in range(max_length):\n","            context = context[:, -self.context_size:] # make sure the context is of size context_size\n","            \n","            if debug:\n","                print(f\"predicting on context: {decode(context[0].tolist())}\")\n","            \n","            logits = self(context) # B*T x vocab_size --> 1*2 x vocab_size\n","            logits = logits[-1, :].view(1, self.vocab_size) # only take the prediction for the last character\n","            percents = torch.softmax(logits, dim=1) # 1*2xvocab_size\n","            pred = torch.multinomial(percents, num_samples=1) \n","            full_text += decode(pred.tolist()[0])\n","            context = torch.cat([context, pred], dim=1) # add to the context dimension instead of the batch dim\n","            \n","        return full_text\n"]},{"cell_type":"code","execution_count":18,"id":"32d21748","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:28.045744Z","iopub.status.busy":"2024-07-11T00:04:28.045505Z","iopub.status.idle":"2024-07-11T00:04:28.057931Z","shell.execute_reply":"2024-07-11T00:04:28.05703Z"},"papermill":{"duration":0.023669,"end_time":"2024-07-11T00:04:28.059955","exception":false,"start_time":"2024-07-11T00:04:28.036286","status":"completed"},"tags":[]},"outputs":[],"source":["class model_generator:\n","    def __init__(self, model: object, max_length: int, num_samples: int, vocab_size: int):\n","        self.model = model\n","        self.max_length = max_length\n","        self.num_samples = num_samples\n","        self.vocab_size = vocab_size\n","        \n","        self.last_output = \"\"\n","        \n","        self.params_dict = {\n","            \"model\": model,\n","            \"max_length\": max_length,\n","            \"num_samples\": num_samples,\n","            \"previous_outputs\": []\n","        }\n","    \n","    @torch.no_grad\n","    def generate(self, starting_char: str = None, clear_outputs: bool = True, debug: bool = False):\n","        self.model.eval()\n","        \n","        if clear_outputs:\n","            self.clear_ouptuts()\n","            \n","        if starting_char is None:\n","            starting_char = decode([torch.randint(0, vocab_size, (1,)).item()])\n","            \n","        for _ in range(self.num_samples):\n","            starting_idx = torch.tensor(encode(starting_char), dtype=torch.long).view(1, 1)\n","            output = self.model.generate(starting_idx=starting_idx, max_length=self.max_length, debug=debug)\n","            self.params_dict[\"previous_outputs\"].append(output)\n","            self.last_output = output\n","    \n","    def update_params(self, model: object = None, max_length: int = None, num_samples: int = None, clear_outputs: bool = None):\n","        if clear_outputs:\n","            self.clear_outputs()\n","            \n","        updated_dict = {\n","            \"model\": model,\n","            \"max_length\": max_length,\n","            \"num_samples\": num_samples\n","        }\n","        \n","        for attribute, value in updated_dict.items():\n","            if value is not None:\n","                self.params_dict[attribute] = value\n","                setattr(self, attribute, value)\n","    \n","    def clear_ouptuts(self):\n","        self.params_dict[\"previous_outputs\"] = []\n","        self.last_output = \"\"\n","        \n","    def print_outputs(self, last: bool = None):\n","        if last:\n","            print(self.last_output)\n","        else:\n","            for output in self.params_dict[\"previous_outputs\"]:\n","                print(f\"{output}\\n\\n\")"]},{"cell_type":"code","execution_count":19,"id":"e4c2f739","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:28.077399Z","iopub.status.busy":"2024-07-11T00:04:28.077133Z","iopub.status.idle":"2024-07-11T00:04:29.435809Z","shell.execute_reply":"2024-07-11T00:04:29.434957Z"},"papermill":{"duration":1.369933,"end_time":"2024-07-11T00:04:29.438103","exception":false,"start_time":"2024-07-11T00:04:28.06817","status":"completed"},"tags":[]},"outputs":[],"source":["n_embd = 784\n","vocab_size = len(vocab)\n","context_size = 128 # same as previously set\n","num_sa_heads = 16\n","sa_head_size = 64\n","\n","decoder = Decoder(vocab_size=vocab_size, n_embd=n_embd, context_size=context_size, num_sa_heads=num_sa_heads, sa_head_size=sa_head_size)\n","optimizer = torch.optim.Adam(params=decoder.parameters(), lr=1e-3)\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":20,"id":"54648b42","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:29.456228Z","iopub.status.busy":"2024-07-11T00:04:29.455541Z","iopub.status.idle":"2024-07-11T00:04:29.459772Z","shell.execute_reply":"2024-07-11T00:04:29.45894Z"},"papermill":{"duration":0.015348,"end_time":"2024-07-11T00:04:29.461704","exception":false,"start_time":"2024-07-11T00:04:29.446356","status":"completed"},"tags":[]},"outputs":[],"source":["decoder_generator = model_generator(model=decoder, max_length=32, num_samples=1, vocab_size=vocab_size)"]},{"cell_type":"code","execution_count":21,"id":"93a643ef","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:29.479061Z","iopub.status.busy":"2024-07-11T00:04:29.47882Z","iopub.status.idle":"2024-07-11T00:04:30.523901Z","shell.execute_reply":"2024-07-11T00:04:30.522792Z"},"papermill":{"duration":1.056912,"end_time":"2024-07-11T00:04:30.526551","exception":false,"start_time":"2024-07-11T00:04:29.469639","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["rnKPkvRm$AUSplMJ?IrCuBLpXBK\n","gZO?q\n","\n","\n"]}],"source":["#decoder_generator.update_params(max_length=100, num_samples=1)\n","decoder_generator.generate()\n","decoder_generator.print_outputs()"]},{"cell_type":"code","execution_count":22,"id":"17488317","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:30.544976Z","iopub.status.busy":"2024-07-11T00:04:30.544112Z","iopub.status.idle":"2024-07-11T00:04:30.72883Z","shell.execute_reply":"2024-07-11T00:04:30.727736Z"},"papermill":{"duration":0.196142,"end_time":"2024-07-11T00:04:30.730945","exception":false,"start_time":"2024-07-11T00:04:30.534803","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(4.3425, device='cuda:0')\n"]}],"source":["decoder.eval()\n","test_loss_fn = nn.CrossEntropyLoss()\n","batch_sample_inputs, batch_sample_labels = next(iter(train_dataloader))\n","with torch.inference_mode():\n","    #print(batch_sample_inputs)\n","    #print(batch_sample_labels)\n","    logits = decoder(batch_sample_inputs)\n","    labels = batch_sample_labels.view(-1) # turns the label shape into a B*T\n","    #print(logits) # 4 batches of 8 characters each, the model is trying to predict the next sequence\n","    #print(labels)\n","    loss = test_loss_fn(logits, batch_sample_labels.view(-1))\n","    print(loss)"]},{"cell_type":"code","execution_count":23,"id":"af58529a","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:30.749191Z","iopub.status.busy":"2024-07-11T00:04:30.748898Z","iopub.status.idle":"2024-07-11T00:04:30.755096Z","shell.execute_reply":"2024-07-11T00:04:30.754295Z"},"papermill":{"duration":0.017365,"end_time":"2024-07-11T00:04:30.757083","exception":false,"start_time":"2024-07-11T00:04:30.739718","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model(model, dataloader, loss_fn, optimizer, epochs):\n","    model.train()\n","    \n","    for epoch in range(epochs):\n","        for batch, (X, y) in tqdm(enumerate(dataloader)):\n","            logits = model(X) # shape of B*T x vocab_size\n","            labels = y.view(-1) # shape of B*T --> each character has it's own prediction\n","            loss = loss_fn(logits, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            if batch % 100 == 0:\n","                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")"]},{"cell_type":"code","execution_count":24,"id":"1a495efa","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:04:30.774103Z","iopub.status.busy":"2024-07-11T00:04:30.773845Z","iopub.status.idle":"2024-07-11T00:22:19.731815Z","shell.execute_reply":"2024-07-11T00:22:19.730452Z"},"papermill":{"duration":1068.968814,"end_time":"2024-07-11T00:22:19.733798","exception":false,"start_time":"2024-07-11T00:04:30.764984","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["1it [00:00,  2.59it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 4.361568927764893 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:23,  4.33it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 2.4810991287231445 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:46,  4.14it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 2.20521879196167 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:47,  4.33it/s]\n","1it [00:00,  4.14it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 2.21132493019104 at epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:24,  4.03it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.9597002267837524 at epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.80it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.8027087450027466 at epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  4.01it/s]\n","1it [00:00,  3.87it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.7473392486572266 at epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:27,  3.69it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.735757827758789 at epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:53,  3.80it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.6752307415008545 at epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:54,  3.75it/s]\n","1it [00:00,  3.87it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.557845115661621 at epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.5470411777496338 at epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.75it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.6084872484207153 at epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.82it/s]\n","1it [00:00,  3.75it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.5185537338256836 at epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.4281761646270752 at epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:53,  3.77it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.4587103128433228 at epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.80it/s]\n","1it [00:00,  3.81it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.4311699867248535 at epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.4260568618774414 at epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.77it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.415411114692688 at epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n","1it [00:00,  3.83it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.3092536926269531 at epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.76it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.4066685438156128 at epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:53,  3.76it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.2929439544677734 at epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:54,  3.79it/s]\n","1it [00:00,  3.84it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.2929799556732178 at epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.2788715362548828 at epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:53,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.2940754890441895 at epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.80it/s]\n","1it [00:00,  3.85it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.1887211799621582 at epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.2219927310943604 at epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.2758433818817139 at epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n","1it [00:00,  3.91it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.119668960571289 at epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.77it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.1692415475845337 at epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.76it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.2558178901672363 at epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n","1it [00:00,  3.84it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.061602234840393 at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.112863302230835 at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.77it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.1433919668197632 at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n","1it [00:00,  3.81it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.029674768447876 at epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.80it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.0813753604888916 at epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.1094677448272705 at epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n","1it [00:00,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.920134425163269 at epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.77it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.0397216081619263 at epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.0370795726776123 at epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n","1it [00:00,  3.80it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.8501040935516357 at epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.77it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.9073486924171448 at epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.984785258769989 at epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n","1it [00:00,  3.87it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.7806637287139893 at epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.8624745011329651 at epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.855772852897644 at epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n","1it [00:00,  3.81it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.6865339875221252 at epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.7341650128364563 at epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.8220940232276917 at epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n","1it [00:00,  3.90it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.5495465397834778 at epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.6301834583282471 at epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.7209587097167969 at epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n","1it [00:00,  3.89it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.45450475811958313 at epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.556039571762085 at epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.6120920181274414 at epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n","1it [00:00,  3.91it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.3820245563983917 at epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.77it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.48824411630630493 at epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.5217015147209167 at epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n","1it [00:00,  3.81it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.35087838768959045 at epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:26,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.3872120976448059 at epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:52,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.459830105304718 at epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:53,  3.81it/s]\n"]}],"source":["train_model(model=decoder, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, epochs=20)"]},{"cell_type":"code","execution_count":25,"id":"7e9b0dbf","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:22:20.405089Z","iopub.status.busy":"2024-07-11T00:22:20.404725Z","iopub.status.idle":"2024-07-11T00:23:09.618169Z","shell.execute_reply":"2024-07-11T00:23:09.617125Z"},"papermill":{"duration":49.887107,"end_time":"2024-07-11T00:23:09.954788","exception":false,"start_time":"2024-07-11T00:22:20.067681","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["generating 5 sample of 500 characters each\n","And I wash atting wart confest; thou sway one\n","It is canno arms of hath been such a jevy\n","Too slew that pay your mants of happy soul.\n","\n","CLARENCE:\n","That breat not une is when I can by him ere\n","To come the buried to see him I tall of York\n","Whostly accountryman: eyest, I have hearts,\n","I'll my vice and a heart's name is land all.\n","\n","ARIVLLET:\n","There is to see it.\n","\n","KING RICHARD III:\n","Then lame the mirth all my largarden's lady\n","And take a pinghambiar of moress' tond.\n","I, in that is I than seizard from me, and then\n","\n","\n","AR-ICLARD Io:\n","Why comes this?\n","\n","MARCIUS:\n","Are you done for me;\n","And, by therefore come, my lord, which not make\n","To make your shield mellast upon is of me.\n","\n","CLARENCE:\n","\n","QUEEN MARGARET:\n","Then I, I can I darly in that die, of heavenment\n","That I charge and be my eyes together.\n","\n","GLOUCESTER:\n","Thy widow as I instrument.\n","\n","LADY ANNE:\n","I thought meet then shall have heart most go.\n","\n","GLOUCESTER:\n","I do not seek bite merift.\n","\n","LADY GLO:\n","Then flow see there mean there rememberlands my leave\n","Then I'll not accompany.\n","\n","MIRA\n","\n","\n","And of judgment continied, thou dost not perfer:\n","Let us be may be put of this death, sir.\n","Thy natus, yiul wait upon me; you know'd--\n","\n","KING RICHARD III:\n","Lo, bitions must kill't-broth, my weak hand--\n","\n","DUFHERMIONE:O:\n","Nay, if I do be this beness to my love,\n","Thought me seek trought much ere be secrount:\n","I'll may it meet the meants.\n","Look birth, fie pastifice gates his no see;\n","Desires are nor me.\n","Let not seeme sorrow fellow, she had ever\n","not him: therefold his embral of I can he for\n","oplete and constrous\n","\n","\n","A\n","love of your sight? Is it shall breed up the will so?\n","\n","VIRGILIA:\n","O, for the grown of my cale.\n","\n","VINCENTIO:\n","Good nevery after and harm.\n","\n","LUCIO:\n","More prayal thereby winterchance, doubio.\n","\n","LUCIO:\n","Consome patient, met me as who rest periance\n","I than have or into are a darkn. ross! Alas, I have\n","hence; ; I'll in that what may shall die is bound\n","With ben virtue more of Clard's plain;\n","TiAlan country be rank, whose burn is several top\n","Lerve't: he, what would is hath been to little eye?\n","What would you must\n","\n","\n","And all they shall not person here.\n","\n","TRANIO:\n","If I that shall not me frunt my fay, but my true\n","Latient from that all found it again.\n","Most unurina,\n","Liest To breat hope more stifit their names.\n","Illing names, what will I died told in thine eye\n","This real apparel honour: he standing his mine\n","That heart us bring as I too you.\n","\n","DUCHESS OF YORK:\n","Ay, yet must I the wart.\n","\n","GLOUCESTER:\n","More ports together, my lord liven doublood to low,\n","I have left am hurt Confulsh afterfy conspirite;\n","To do the prince the wi\n","\n","\n"]}],"source":["print(\"generating 5 sample of 500 characters each\")\n","\n","decoder_generator.update_params(max_length=500, num_samples=5)\n","decoder_generator.generate()\n","decoder_generator.print_outputs()"]},{"cell_type":"markdown","id":"b5d5dc80","metadata":{"papermill":{"duration":0.33419,"end_time":"2024-07-11T00:23:10.666226","exception":false,"start_time":"2024-07-11T00:23:10.332036","status":"completed"},"tags":[]},"source":["# Save and load the model"]},{"cell_type":"code","execution_count":26,"id":"a9f43894","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:23:11.329512Z","iopub.status.busy":"2024-07-11T00:23:11.329144Z","iopub.status.idle":"2024-07-11T00:23:11.554771Z","shell.execute_reply":"2024-07-11T00:23:11.553752Z"},"papermill":{"duration":0.560897,"end_time":"2024-07-11T00:23:11.557247","exception":false,"start_time":"2024-07-11T00:23:10.99635","status":"completed"},"tags":[]},"outputs":[],"source":["# save the model\n","torch.save(decoder.state_dict(), \"./models/shakespeare_like_text_generator.pt\")"]},{"cell_type":"code","execution_count":27,"id":"0d8a8d5b","metadata":{"execution":{"iopub.execute_input":"2024-07-11T00:23:12.221137Z","iopub.status.busy":"2024-07-11T00:23:12.220782Z","iopub.status.idle":"2024-07-11T00:23:18.631523Z","shell.execute_reply":"2024-07-11T00:23:18.630474Z"},"papermill":{"duration":6.743429,"end_time":"2024-07-11T00:23:18.633648","exception":false,"start_time":"2024-07-11T00:23:11.890219","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CESTER:\n","I go; and if you plant deserved\n","The Katharina, did I know not him princ.\n","\n","KING EDWARD IV:\n","This off that he be offence, that approached their\n","Thou shalt the tertainmed traitor flatter.\n","\n","RICHARD:\n","Marriumph, help in earth, heaving thee, my lord\n","Death is heaven; for what my would languance\n","And Baptista'e maint blood\n","\n","\n"]}],"source":["n_embd = 784\n","vocab_size = len(vocab)\n","context_size = 128 # same as previously set\n","num_sa_heads = 16\n","sa_head_size = 64\n","\n","test_model = Decoder(vocab_size=vocab_size, n_embd=n_embd, context_size=context_size, num_sa_heads=num_sa_heads, sa_head_size=sa_head_size)\n","\n","test_model.load_state_dict(torch.load(\"./models/shakespeare_like_text_generator.pt\"))\n","test_model_generator = model_generator(model=test_model, max_length=320, num_samples=1, vocab_size=vocab_size) \n","test_model_generator.generate()\n","test_model_generator.print_outputs()\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5339176,"sourceId":8871363,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":1141.881742,"end_time":"2024-07-11T00:23:20.088122","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-11T00:04:18.20638","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}