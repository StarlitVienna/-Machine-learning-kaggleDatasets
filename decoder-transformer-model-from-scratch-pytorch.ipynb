{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/evelynartoria/decoder-transformer-model-from-scratch-pytorch?scriptVersionId=187738267\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"b0018f93","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:37.709419Z","iopub.status.busy":"2024-07-11T01:59:37.709076Z","iopub.status.idle":"2024-07-11T01:59:38.723222Z","shell.execute_reply":"2024-07-11T01:59:38.722109Z"},"papermill":{"duration":1.026255,"end_time":"2024-07-11T01:59:38.72562","exception":false,"start_time":"2024-07-11T01:59:37.699365","status":"completed"},"tags":[]},"outputs":[],"source":["!mkdir ./models"]},{"cell_type":"code","execution_count":2,"id":"e410a857","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:38.743399Z","iopub.status.busy":"2024-07-11T01:59:38.743085Z","iopub.status.idle":"2024-07-11T01:59:43.301775Z","shell.execute_reply":"2024-07-11T01:59:43.300836Z"},"papermill":{"duration":4.570282,"end_time":"2024-07-11T01:59:43.304198","exception":false,"start_time":"2024-07-11T01:59:38.733916","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":3,"id":"801a80eb","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:43.3224Z","iopub.status.busy":"2024-07-11T01:59:43.322008Z","iopub.status.idle":"2024-07-11T01:59:43.407365Z","shell.execute_reply":"2024-07-11T01:59:43.40631Z"},"papermill":{"duration":0.097043,"end_time":"2024-07-11T01:59:43.409334","exception":false,"start_time":"2024-07-11T01:59:43.312291","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["default device set to cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","generator = torch.Generator(device=device)\n","torch.set_default_device(device)\n","print(f\"default device set to {device}\")"]},{"cell_type":"code","execution_count":4,"id":"069a07db","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:43.426575Z","iopub.status.busy":"2024-07-11T01:59:43.42628Z","iopub.status.idle":"2024-07-11T01:59:43.466641Z","shell.execute_reply":"2024-07-11T01:59:43.465936Z"},"papermill":{"duration":0.05103,"end_time":"2024-07-11T01:59:43.468543","exception":false,"start_time":"2024-07-11T01:59:43.417513","status":"completed"},"tags":[]},"outputs":[],"source":["with open(\"/kaggle/input/shakespeare/input.txt\", 'r', encoding=\"utf-8\") as f:\n","    text = f.read()"]},{"cell_type":"code","execution_count":5,"id":"30aa764c","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:43.48626Z","iopub.status.busy":"2024-07-11T01:59:43.48599Z","iopub.status.idle":"2024-07-11T01:59:43.504821Z","shell.execute_reply":"2024-07-11T01:59:43.504073Z"},"papermill":{"duration":0.029683,"end_time":"2024-07-11T01:59:43.506824","exception":false,"start_time":"2024-07-11T01:59:43.477141","status":"completed"},"tags":[]},"outputs":[],"source":["vocab = sorted(set(text))\n","vocab_size = len(vocab)"]},{"cell_type":"code","execution_count":6,"id":"7b1a9f2b","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:43.523688Z","iopub.status.busy":"2024-07-11T01:59:43.523412Z","iopub.status.idle":"2024-07-11T01:59:43.528336Z","shell.execute_reply":"2024-07-11T01:59:43.527533Z"},"papermill":{"duration":0.015699,"end_time":"2024-07-11T01:59:43.530459","exception":false,"start_time":"2024-07-11T01:59:43.51476","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["46\n","h\n"]}],"source":["stoi = {c: v for v, c in enumerate(vocab)}\n","itos = {v: c for c, v in stoi.items()}\n","\n","print(stoi[\"h\"])\n","print(itos[46])"]},{"cell_type":"code","execution_count":7,"id":"a758cdda","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:43.548338Z","iopub.status.busy":"2024-07-11T01:59:43.548051Z","iopub.status.idle":"2024-07-11T01:59:43.553389Z","shell.execute_reply":"2024-07-11T01:59:43.552574Z"},"papermill":{"duration":0.016831,"end_time":"2024-07-11T01:59:43.555323","exception":false,"start_time":"2024-07-11T01:59:43.538492","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[46, 43, 50, 50, 53, 1, 46, 53, 61, 1, 39, 56, 43, 1, 63, 53, 59, 12] hello how are you?\n"]}],"source":["encode = lambda e: [stoi[ch] for ch in e]\n","decode = lambda d: \"\".join([itos[idx] for idx in d])\n","\n","encoded = encode(\"hello how are you?\")\n","decoded = decode(encoded)\n","\n","print(encoded, decoded)"]},{"cell_type":"code","execution_count":8,"id":"4de3c1cf","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:43.572264Z","iopub.status.busy":"2024-07-11T01:59:43.571998Z","iopub.status.idle":"2024-07-11T01:59:43.957796Z","shell.execute_reply":"2024-07-11T01:59:43.9568Z"},"papermill":{"duration":0.396757,"end_time":"2024-07-11T01:59:43.960001","exception":false,"start_time":"2024-07-11T01:59:43.563244","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([6656, 2304,  896, 5888, 8704, 2816, 2560, 9472, 3712, 9728, 8448, 8064,\n","        3968, 8576, 4992, 8960, 8192, 6272, 4608, 3200, 3072, 6144, 3840, 9856,\n","        9088, 1792, 2176, 2688, 3584, 6400, 9216, 6912, 5120, 7424, 4864, 7808,\n","        7168, 7040, 2432, 4352, 5248, 2048, 4480, 7680,  768, 7552, 4096, 1920,\n","         256, 7296, 9344, 1664, 5632, 2944, 5504, 4224, 3328, 8320, 4736, 1152,\n","        9600, 7936,  640,  512, 6784,  128, 1280,    0, 5376, 1024, 3456, 5760,\n","         384, 1408, 6016, 8832, 6528, 1536], device='cuda:0')\n"]}],"source":["context_size = 128\n","random_idx_tensor = torch.randperm(10000//context_size) * context_size\n","print(random_idx_tensor)"]},{"cell_type":"code","execution_count":9,"id":"daef08d4","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:43.977453Z","iopub.status.busy":"2024-07-11T01:59:43.977155Z","iopub.status.idle":"2024-07-11T01:59:43.98289Z","shell.execute_reply":"2024-07-11T01:59:43.982054Z"},"papermill":{"duration":0.016512,"end_time":"2024-07-11T01:59:43.984684","exception":false,"start_time":"2024-07-11T01:59:43.968172","status":"completed"},"tags":[]},"outputs":[],"source":["def make_dataset(data):\n","    random_idx_tensor = torch.randperm((len(data)-context_size)//context_size) * context_size\n","    inputs = torch.stack([data[idx:idx+context_size] for idx in random_idx_tensor])\n","    labels = torch.stack([data[idx+1:idx+context_size+1] for idx in random_idx_tensor])\n","    \n","    return TensorDataset(inputs.to(torch.long), labels.to(torch.long))"]},{"cell_type":"code","execution_count":10,"id":"c9a1d048","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:44.002331Z","iopub.status.busy":"2024-07-11T01:59:44.001889Z","iopub.status.idle":"2024-07-11T01:59:45.927362Z","shell.execute_reply":"2024-07-11T01:59:45.926195Z"},"papermill":{"duration":1.936698,"end_time":"2024-07-11T01:59:45.929546","exception":false,"start_time":"2024-07-11T01:59:43.992848","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([43,  5, 57,  1, 58, 53,  1, 57, 53, 61,  8,  0,  0, 28, 56, 53, 60, 53,\n","        57, 58, 10,  0, 15, 53, 51, 43,  1, 46, 47, 58, 46, 43, 56,  6,  1, 57,\n","        47, 56, 56, 39, 46,  8,  1, 15, 39, 52,  1, 63, 53, 59,  1, 41, 59, 58,\n","         1, 53, 44, 44,  1, 39,  1, 51, 39, 52,  5, 57,  1, 46, 43, 39, 42, 12,\n","         0,  0, 28, 27, 25, 28, 17, 37, 10,  0, 21, 44,  1, 58, 46, 43,  1, 51,\n","        39, 52,  1, 40, 43,  1, 39,  1, 40, 39, 41, 46, 43, 50, 53, 56,  6,  1,\n","        57, 47, 56,  6,  1, 21,  1, 41, 39, 52, 11,  1, 40, 59, 58,  1, 47, 44,\n","         1, 46], device='cuda:0')\n","tensor([ 5, 57,  1, 58, 53,  1, 57, 53, 61,  8,  0,  0, 28, 56, 53, 60, 53, 57,\n","        58, 10,  0, 15, 53, 51, 43,  1, 46, 47, 58, 46, 43, 56,  6,  1, 57, 47,\n","        56, 56, 39, 46,  8,  1, 15, 39, 52,  1, 63, 53, 59,  1, 41, 59, 58,  1,\n","        53, 44, 44,  1, 39,  1, 51, 39, 52,  5, 57,  1, 46, 43, 39, 42, 12,  0,\n","         0, 28, 27, 25, 28, 17, 37, 10,  0, 21, 44,  1, 58, 46, 43,  1, 51, 39,\n","        52,  1, 40, 43,  1, 39,  1, 40, 39, 41, 46, 43, 50, 53, 56,  6,  1, 57,\n","        47, 56,  6,  1, 21,  1, 41, 39, 52, 11,  1, 40, 59, 58,  1, 47, 44,  1,\n","        46, 43], device='cuda:0')\n","dataset length --> 8713 (1115264 characters), that is, about the length of text 1115394 - context_size --> 1115266\n"]}],"source":["data = torch.tensor(encode(text))\n","dataset = make_dataset(data=data)\n","sample_input = dataset[0][0]\n","sample_label = dataset[0][1]\n","\n","print(sample_input)\n","print(sample_label)\n","\n","print(f\"dataset length --> {len(dataset)} ({len(dataset) * context_size} characters), that is, about the length of text {len(text)} - context_size --> {len(text)-context_size}\")"]},{"cell_type":"code","execution_count":11,"id":"9cac05cc","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:45.949008Z","iopub.status.busy":"2024-07-11T01:59:45.94828Z","iopub.status.idle":"2024-07-11T01:59:45.955593Z","shell.execute_reply":"2024-07-11T01:59:45.954771Z"},"papermill":{"duration":0.019334,"end_time":"2024-07-11T01:59:45.957546","exception":false,"start_time":"2024-07-11T01:59:45.938212","status":"completed"},"tags":[]},"outputs":[],"source":["train_split = int(len(dataset)*0.75)\n","test_split = int(len(dataset)-train_split)\n","\n","train_dataset, test_dataset = random_split(dataset=dataset, lengths=[train_split, test_split], generator=generator)"]},{"cell_type":"code","execution_count":12,"id":"ed4a17f7","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:45.975929Z","iopub.status.busy":"2024-07-11T01:59:45.975214Z","iopub.status.idle":"2024-07-11T01:59:45.980542Z","shell.execute_reply":"2024-07-11T01:59:45.979699Z"},"papermill":{"duration":0.016553,"end_time":"2024-07-11T01:59:45.98268","exception":false,"start_time":"2024-07-11T01:59:45.966127","status":"completed"},"tags":[]},"outputs":[],"source":["batch_size = 32\n","train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, generator=generator)\n","test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, generator=generator)"]},{"cell_type":"code","execution_count":13,"id":"cb19488d","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:46.000492Z","iopub.status.busy":"2024-07-11T01:59:46.00022Z","iopub.status.idle":"2024-07-11T01:59:46.009294Z","shell.execute_reply":"2024-07-11T01:59:46.008479Z"},"papermill":{"duration":0.020208,"end_time":"2024-07-11T01:59:46.011167","exception":false,"start_time":"2024-07-11T01:59:45.990959","status":"completed"},"tags":[]},"outputs":[],"source":["class Head(nn.Module):\n","    def __init__(self, n_embd, head_size, context_size):\n","        super(Head, self).__init__()\n","        \n","        self.Q = nn.Linear(in_features=n_embd, out_features=head_size) # takes in BxTxC and return BxTxHead_size\n","        self.K = nn.Linear(in_features=n_embd, out_features=head_size)\n","        self.V = nn.Linear(in_features=n_embd, out_features=head_size)\n","        \n","        self.register_buffer(\"tril\", torch.tril(torch.ones(size=(context_size, context_size))))\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        B, T, C = x.shape # batch_size by context_size by n_embd\n","        q = self.Q(x) # BxTxHead_size\n","        k = self.K(x) # BxTxHead_size\n","        \n","        wei = q @ k.transpose(-2, -1) * (C ** -0.5) # BxTxHead_size @ BxHead_sizexT --> BxTxT then divided by the square root of n_embd\n","        \n","        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # :T and :T is needed in case context is smaller than context_size\n","        wei = torch.softmax(wei, dim=-1)\n","        v = self.V(x) # BxTxHead_size\n","        output = wei @ v # BxTxT @ BxTxHead_size --> BxTxHead_size\n","        \n","        return output"]},{"cell_type":"code","execution_count":14,"id":"da395747","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:46.028874Z","iopub.status.busy":"2024-07-11T01:59:46.028567Z","iopub.status.idle":"2024-07-11T01:59:46.035076Z","shell.execute_reply":"2024-07-11T01:59:46.034155Z"},"papermill":{"duration":0.017577,"end_time":"2024-07-11T01:59:46.036952","exception":false,"start_time":"2024-07-11T01:59:46.019375","status":"completed"},"tags":[]},"outputs":[],"source":["class MultiHeadedAttention(nn.Module):\n","    def __init__(self, n_embd, context_size, n_heads, head_size):\n","        super(MultiHeadedAttention, self).__init__()\n","        self.heads = nn.ModuleList([Head(n_embd=n_embd, head_size=head_size, context_size=context_size) for _ in range(n_heads)]) # BxTx (n_heads * head_size)\n","        self.projection = nn.Linear(in_features=n_heads*head_size, out_features=n_embd) # ensures the output is going to be o shape BxTxn_embd (BxTxC) so that is can go through multiple attention block\n","        \n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = torch.cat([head(x) for head in self.heads], dim=-1) # cat in the Channels dimension; output shape is BxTx (n_heads * head_size)\n","        x = self.projection(x)\n","        return  x"]},{"cell_type":"code","execution_count":15,"id":"a4bdccc2","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:46.054909Z","iopub.status.busy":"2024-07-11T01:59:46.054202Z","iopub.status.idle":"2024-07-11T01:59:46.059701Z","shell.execute_reply":"2024-07-11T01:59:46.059026Z"},"papermill":{"duration":0.016465,"end_time":"2024-07-11T01:59:46.06159","exception":false,"start_time":"2024-07-11T01:59:46.045125","status":"completed"},"tags":[]},"outputs":[],"source":["class FeedForward(nn.Module):\n","    def __init__(self, in_features):\n","        super(FeedForward, self).__init__()\n","        self.ffwrd_layer = nn.Sequential(\n","            nn.Linear(in_features=in_features, out_features=in_features * 4), # scale by 4, according to the attention is all you need paper\n","            nn.ReLU(),\n","            nn.Linear(in_features=in_features * 4, out_features=in_features) # another projection layer\n","        )\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        return self.ffwrd_layer(x)"]},{"cell_type":"code","execution_count":16,"id":"9c04ab36","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:46.079531Z","iopub.status.busy":"2024-07-11T01:59:46.078849Z","iopub.status.idle":"2024-07-11T01:59:46.085451Z","shell.execute_reply":"2024-07-11T01:59:46.084606Z"},"papermill":{"duration":0.017459,"end_time":"2024-07-11T01:59:46.087322","exception":false,"start_time":"2024-07-11T01:59:46.069863","status":"completed"},"tags":[]},"outputs":[],"source":["class Block(nn.Module):\n","    def __init__(self, n_heads, head_size, n_embd, context_size):\n","        super(Block, self).__init__()\n","        self.multiheaded_self_attetion = MultiHeadedAttention(n_embd=n_embd, context_size=context_size, n_heads=n_heads, head_size=head_size) # create a multiheaded attention block; returns shape BxTx (num_heads*head_size)\n","        self.ffwrd = FeedForward(in_features=n_embd)\n","        self.layer_norm1 = nn.LayerNorm(n_embd)\n","        self.layer_norm2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = x + self.multiheaded_self_attetion(self.layer_norm1(x))\n","        x = x + self.ffwrd(self.layer_norm2(x))\n","\n","        return x"]},{"cell_type":"code","execution_count":17,"id":"e07d616c","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:46.105256Z","iopub.status.busy":"2024-07-11T01:59:46.104591Z","iopub.status.idle":"2024-07-11T01:59:46.118017Z","shell.execute_reply":"2024-07-11T01:59:46.117217Z"},"papermill":{"duration":0.024307,"end_time":"2024-07-11T01:59:46.119899","exception":false,"start_time":"2024-07-11T01:59:46.095592","status":"completed"},"tags":[]},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, n_embd, context_size, vocab_size, num_sa_heads, sa_head_size):\n","        super().__init__()\n","        \n","        self.vocab_size = vocab_size\n","        self.context_size = context_size\n","        self.n_embd = n_embd\n","        \n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # each character from the vocab has n_embd values associated to it\n","        self.positional_embedding_table = nn.Embedding(context_size, n_embd) # each character position in the context has n_embd values associated to it\n","        \n","        self.attention_blocks = nn.Sequential(\n","            Block(n_heads=num_sa_heads, head_size=sa_head_size, context_size=self.context_size, n_embd=self.n_embd), # takes in BxTxC, calculate logits of BxTx (num_heads * head_size), then project it as BxTxC\n","            Block(n_heads=num_sa_heads, head_size=sa_head_size, context_size=self.context_size, n_embd=self.n_embd),\n","            Block(n_heads=num_sa_heads, head_size=sa_head_size, context_size=self.context_size, n_embd=self.n_embd),\n","            nn.LayerNorm(n_embd) # normalize the layers\n","        )\n","        \n","\n","        self.lm_head = nn.Linear(in_features=n_embd, out_features=vocab_size) # (B, T, vocab_size)\n","        \n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        B, T = x.shape # batch_size and context_size\n","        positions = torch.arange(start=0, end=T, step=1)\n","        \n","        pos_emb = self.positional_embedding_table(positions) # T x C --> in broadcasting, pytorch adds a batch dim=1\n","        token_emb = self.token_embedding_table(x) # B x T x C\n","        \n","        x = token_emb + pos_emb # BxTxC\n","        x = self.attention_blocks(x) # returns logits of shape BxTx (self.sa_head_size * self.num_sa_heads) projected to BxTxC\n","        x = self.lm_head(x) # BxTxvocab_size --> BxTxHead_size @ BxTxVocab_size return BxTxVocab_size\n","\n","        return x.view(B*T, self.vocab_size) # easier shape to work with the labels\n","    \n","    def generate(self, starting_idx: torch.Tensor, max_length: int, debug: bool) -> torch.Tensor:\n","        full_text = decode([starting_idx.item()])\n","        context = starting_idx\n","        \n","        for _ in range(max_length):\n","            context = context[:, -self.context_size:] # make sure the context is of size context_size\n","            \n","            if debug:\n","                print(f\"predicting on context: {decode(context[0].tolist())}\")\n","            \n","            logits = self(context) # B*T x vocab_size --> 1*2 x vocab_size\n","            logits = logits[-1, :].view(1, self.vocab_size) # only take the prediction for the last character\n","            percents = torch.softmax(logits, dim=1) # 1*2xvocab_size\n","            pred = torch.multinomial(percents, num_samples=1) \n","            full_text += decode(pred.tolist()[0])\n","            context = torch.cat([context, pred], dim=1) # add to the context dimension instead of the batch dim\n","            \n","        return full_text\n"]},{"cell_type":"code","execution_count":18,"id":"916f9a32","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:46.137576Z","iopub.status.busy":"2024-07-11T01:59:46.136991Z","iopub.status.idle":"2024-07-11T01:59:46.14895Z","shell.execute_reply":"2024-07-11T01:59:46.148159Z"},"papermill":{"duration":0.022656,"end_time":"2024-07-11T01:59:46.150797","exception":false,"start_time":"2024-07-11T01:59:46.128141","status":"completed"},"tags":[]},"outputs":[],"source":["class model_generator:\n","    def __init__(self, model: object, max_length: int, num_samples: int, vocab_size: int):\n","        self.model = model\n","        self.max_length = max_length\n","        self.num_samples = num_samples\n","        self.vocab_size = vocab_size\n","        \n","        self.last_output = \"\"\n","        \n","        self.params_dict = {\n","            \"model\": model,\n","            \"max_length\": max_length,\n","            \"num_samples\": num_samples,\n","            \"previous_outputs\": []\n","        }\n","    \n","    @torch.no_grad\n","    def generate(self, starting_char: str = None, clear_outputs: bool = True, debug: bool = False):\n","        self.model.eval()\n","        \n","        if clear_outputs:\n","            self.clear_ouptuts()\n","            \n","        if starting_char is None:\n","            starting_char = decode([torch.randint(0, vocab_size, (1,)).item()])\n","            \n","        for _ in range(self.num_samples):\n","            starting_idx = torch.tensor(encode(starting_char), dtype=torch.long).view(1, 1)\n","            output = self.model.generate(starting_idx=starting_idx, max_length=self.max_length, debug=debug)\n","            self.params_dict[\"previous_outputs\"].append(output)\n","            self.last_output = output\n","    \n","    def update_params(self, model: object = None, max_length: int = None, num_samples: int = None, clear_outputs: bool = None):\n","        if clear_outputs:\n","            self.clear_outputs()\n","            \n","        updated_dict = {\n","            \"model\": model,\n","            \"max_length\": max_length,\n","            \"num_samples\": num_samples\n","        }\n","        \n","        for attribute, value in updated_dict.items():\n","            if value is not None:\n","                self.params_dict[attribute] = value\n","                setattr(self, attribute, value)\n","    \n","    def clear_ouptuts(self):\n","        self.params_dict[\"previous_outputs\"] = []\n","        self.last_output = \"\"\n","        \n","    def print_outputs(self, last: bool = None):\n","        if last:\n","            print(self.last_output)\n","        else:\n","            for output in self.params_dict[\"previous_outputs\"]:\n","                print(f\"{output}\\n\\n\")"]},{"cell_type":"code","execution_count":19,"id":"fb087191","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:46.168062Z","iopub.status.busy":"2024-07-11T01:59:46.167809Z","iopub.status.idle":"2024-07-11T01:59:47.827789Z","shell.execute_reply":"2024-07-11T01:59:47.827006Z"},"papermill":{"duration":1.671204,"end_time":"2024-07-11T01:59:47.830016","exception":false,"start_time":"2024-07-11T01:59:46.158812","status":"completed"},"tags":[]},"outputs":[],"source":["n_embd = 784\n","vocab_size = len(vocab)\n","context_size = 128 # same as previously set\n","num_sa_heads = 16\n","sa_head_size = 64\n","\n","decoder = Decoder(vocab_size=vocab_size, n_embd=n_embd, context_size=context_size, num_sa_heads=num_sa_heads, sa_head_size=sa_head_size)\n","optimizer = torch.optim.Adam(params=decoder.parameters(), lr=1e-3)\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":20,"id":"56a2306f","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:47.848065Z","iopub.status.busy":"2024-07-11T01:59:47.847679Z","iopub.status.idle":"2024-07-11T01:59:47.851978Z","shell.execute_reply":"2024-07-11T01:59:47.851166Z"},"papermill":{"duration":0.015325,"end_time":"2024-07-11T01:59:47.853983","exception":false,"start_time":"2024-07-11T01:59:47.838658","status":"completed"},"tags":[]},"outputs":[],"source":["decoder_generator = model_generator(model=decoder, max_length=32, num_samples=1, vocab_size=vocab_size)"]},{"cell_type":"code","execution_count":21,"id":"6b96d5be","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:47.872198Z","iopub.status.busy":"2024-07-11T01:59:47.87152Z","iopub.status.idle":"2024-07-11T01:59:49.10016Z","shell.execute_reply":"2024-07-11T01:59:49.098915Z"},"papermill":{"duration":1.2404,"end_time":"2024-07-11T01:59:49.102829","exception":false,"start_time":"2024-07-11T01:59:47.862429","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["plMoNKZi$KabPMAAEgD;KP\n","z$ ;X\n","dBi\n","\n","\n","\n"]}],"source":["#decoder_generator.update_params(max_length=100, num_samples=1)\n","decoder_generator.generate()\n","decoder_generator.print_outputs()"]},{"cell_type":"code","execution_count":22,"id":"e15a00eb","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:49.122503Z","iopub.status.busy":"2024-07-11T01:59:49.121862Z","iopub.status.idle":"2024-07-11T01:59:49.329536Z","shell.execute_reply":"2024-07-11T01:59:49.32856Z"},"papermill":{"duration":0.219163,"end_time":"2024-07-11T01:59:49.331586","exception":false,"start_time":"2024-07-11T01:59:49.112423","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(4.3012, device='cuda:0')\n"]}],"source":["decoder.eval()\n","test_loss_fn = nn.CrossEntropyLoss()\n","batch_sample_inputs, batch_sample_labels = next(iter(train_dataloader))\n","with torch.inference_mode():\n","    #print(batch_sample_inputs)\n","    #print(batch_sample_labels)\n","    logits = decoder(batch_sample_inputs)\n","    labels = batch_sample_labels.view(-1) # turns the label shape into a B*T\n","    #print(logits) # 4 batches of 8 characters each, the model is trying to predict the next sequence\n","    #print(labels)\n","    loss = test_loss_fn(logits, batch_sample_labels.view(-1))\n","    print(loss)"]},{"cell_type":"code","execution_count":23,"id":"a202608b","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:49.349718Z","iopub.status.busy":"2024-07-11T01:59:49.349439Z","iopub.status.idle":"2024-07-11T01:59:49.355425Z","shell.execute_reply":"2024-07-11T01:59:49.354633Z"},"papermill":{"duration":0.017201,"end_time":"2024-07-11T01:59:49.357218","exception":false,"start_time":"2024-07-11T01:59:49.340017","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model(model, dataloader, loss_fn, optimizer, epochs):\n","    model.train()\n","    \n","    for epoch in range(epochs):\n","        for batch, (X, y) in tqdm(enumerate(dataloader)):\n","            logits = model(X) # shape of B*T x vocab_size\n","            labels = y.view(-1) # shape of B*T --> each character has it's own prediction\n","            loss = loss_fn(logits, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            if batch % 100 == 0:\n","                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")"]},{"cell_type":"code","execution_count":24,"id":"93dcecf9","metadata":{"execution":{"iopub.execute_input":"2024-07-11T01:59:49.374692Z","iopub.status.busy":"2024-07-11T01:59:49.374433Z","iopub.status.idle":"2024-07-11T02:16:39.602591Z","shell.execute_reply":"2024-07-11T02:16:39.601655Z"},"papermill":{"duration":1010.239098,"end_time":"2024-07-11T02:16:39.604658","exception":false,"start_time":"2024-07-11T01:59:49.36556","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["1it [00:00,  2.38it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 4.3230791091918945 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:22,  4.43it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 2.4952898025512695 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:45,  4.33it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 2.2436976432800293 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:46,  4.43it/s]\n","1it [00:00,  4.32it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 2.181868314743042 at epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:23,  4.21it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.995511770248413 at epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:47,  4.09it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.72166109085083 at epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:48,  4.24it/s]\n","1it [00:00,  4.11it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.825104832649231 at epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:24,  3.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.698589563369751 at epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.6682977676391602 at epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  4.01it/s]\n","1it [00:00,  3.92it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.5682876110076904 at epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.05it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.6100648641586304 at epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:49,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.6017972230911255 at epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.05it/s]\n","1it [00:00,  4.03it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.4753879308700562 at epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.415902018547058 at epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.4691063165664673 at epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  4.01it/s]\n","1it [00:00,  4.04it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.4025795459747314 at epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.4091607332229614 at epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:49,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.4854360818862915 at epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.04it/s]\n","1it [00:00,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.3166743516921997 at epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.98it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.3324304819107056 at epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.3443679809570312 at epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  4.01it/s]\n","1it [00:00,  3.98it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.2808433771133423 at epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.00it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.3003160953521729 at epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  4.00it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.3413220643997192 at epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.02it/s]\n","1it [00:00,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.242486596107483 at epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.00it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.2870001792907715 at epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  4.00it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.2393996715545654 at epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.02it/s]\n","1it [00:00,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.1703169345855713 at epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.2035621404647827 at epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.2139416933059692 at epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.03it/s]\n","1it [00:00,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.0516431331634521 at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.1842637062072754 at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:49,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.1409140825271606 at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.03it/s]\n","1it [00:00,  4.03it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.0247409343719482 at epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.0253081321716309 at epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:49,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.1303226947784424 at epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.04it/s]\n","1it [00:00,  3.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.88817298412323 at epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.00it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.992388904094696 at epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:49,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.0694316625595093 at epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.04it/s]\n","1it [00:00,  4.02it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.8838292360305786 at epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.9680342078208923 at epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:49,  4.02it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.9759601354598999 at epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.04it/s]\n","1it [00:00,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.7714415788650513 at epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.00it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.8669955730438232 at epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.898356556892395 at epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.03it/s]\n","1it [00:00,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.7013464570045471 at epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.721276044845581 at epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:49,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.8632165193557739 at epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.04it/s]\n","1it [00:00,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.6010428667068481 at epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.02it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.6803231239318848 at epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:49,  4.02it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.7550438642501831 at epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.03it/s]\n","1it [00:00,  3.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.4882310628890991 at epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.6192662715911865 at epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:49,  4.02it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.6561490297317505 at epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.03it/s]\n","1it [00:00,  4.04it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.42731937766075134 at epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.494682639837265 at epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:49,  4.00it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.593704104423523 at epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.04it/s]\n","1it [00:00,  3.93it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.36597058176994324 at epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  4.02it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.4475789964199066 at epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:49,  4.02it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.49575209617614746 at epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:50,  4.04it/s]\n"]}],"source":["train_model(model=decoder, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, epochs=20)"]},{"cell_type":"code","execution_count":25,"id":"6e3b9fad","metadata":{"execution":{"iopub.execute_input":"2024-07-11T02:16:40.290624Z","iopub.status.busy":"2024-07-11T02:16:40.290264Z","iopub.status.idle":"2024-07-11T02:17:28.533752Z","shell.execute_reply":"2024-07-11T02:17:28.532775Z"},"papermill":{"duration":48.92567,"end_time":"2024-07-11T02:17:28.863871","exception":false,"start_time":"2024-07-11T02:16:39.938201","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["generating 5 sample of 500 characters each\n","u, since you mercy dent you, sir?\n","\n","of I thank you.\n","\n","DUCHESS OF YORK:\n","My lord sob deservice, but not lord; and now,\n","Be cold Mowbray he for he standing to bewish;\n","And think ither lets him an a frant, and hour\n","Let him by nally. What with all men a!--\n","\n","PETRUCHIO:\n","O let's stridle! There with all not come,' sweet:\n","All thing she is breakness to the limb,\n","And a gone and forcer and ro age.\n","\n","FRIAR LAURENCE:\n","I cannot me: better was you.\n","This my demand you.\n","\n","ROMMO:\n","This lord: he is is the man conservest, sir\n","\n","\n","umber gent for plaints,\n","Your discontenting, and grace the quality;\n","Your poor is good dares not and when men\n","Romansport the sale way; I will go, sir.\n","\n","ROMEO:\n","A lean good this is the where is sweet lies: if the will\n","will Ie let me lappy thee: if an he stay, he's\n","But lets it noy the such a maken nentreature\n","Hell I cominius 'dies '' the land. Your move,\n","A mong and enough even so man alliant home;\n","And fall he stay it be so walk'd with Lord And\n","That he and claim you, for would so grewest,\n","Before you de\n","\n","\n","usurps;\n","I'll recore you shall , and be both them.\n","\n","JULIET:\n","Mast my tongue!\n","I never me how I return for a man arry go\n","I!\n","And for as I will at grant no me.\n","\n","POLIXENES:\n","Year :BY and so.\n","\n","BRATHARINA:\n","Had say, in myself, what I stand you?\n","\n","PETRUCHIO:\n","They?\n","\n","BENVOLUMNIO:\n","Twise! it wink, said! he simpless she stand.\n","\n","LARTIUS:\n","We'll to go the strang so wind rugh, hear\n","To but a purence; she have shed by your conver:\n","Antill him exile it mary at Rome;\n","And here are renof ic seeming so sileness.\n","\n","ROMIO:\n","I wou\n","\n","\n","uoth my soul.\n","What you'll do with me to slept me some.\n","\n","HORTENSIO:\n","Believe more; but I'll not, but you her no use a\n","cruble, sir, which, which wild care no much;\n","And I read you will af my what you threwear,\n","Renough; which is an im so, for a little\n","In bring and a she and know who shed but when here,\n","More a mant for gown his wiftly body purse.\n","\n","ARIEL:\n","Yet wonder down all that seem.\n","Be me sleeping winds down within a\n","greatnessent for a love; be newell hole!\n","\n","RICHARD:\n","A D:\n","You call down, my own.\n","\n","DUCH\n","\n","\n","ure were her was are sport, starvell'd Mercury once\n","That habove the unstruth's faci:\n","God calm of you in the displain of dinners,\n","Madam Lord Walliam whing clouds of your mend,\n","And wantongue mether since follow in itself.\n","A what which he is is will will accurse\n","The and what above and look upon his lear!\n","And event what and gently consented grant\n","All boing honest thou black upon he; and there\n","To bid him for the crown within indeed,\n","When gold in God harm God,\n","And ther their such absent forget flouces \n","\n","\n"]}],"source":["print(\"generating 5 sample of 500 characters each\")\n","\n","decoder_generator.update_params(max_length=500, num_samples=5)\n","decoder_generator.generate()\n","decoder_generator.print_outputs()"]},{"cell_type":"markdown","id":"2776a4a7","metadata":{"papermill":{"duration":0.353192,"end_time":"2024-07-11T02:17:29.557418","exception":false,"start_time":"2024-07-11T02:17:29.204226","status":"completed"},"tags":[]},"source":["# Save and load the model"]},{"cell_type":"code","execution_count":26,"id":"552b34bb","metadata":{"execution":{"iopub.execute_input":"2024-07-11T02:17:30.307425Z","iopub.status.busy":"2024-07-11T02:17:30.307055Z","iopub.status.idle":"2024-07-11T02:17:30.531784Z","shell.execute_reply":"2024-07-11T02:17:30.530704Z"},"papermill":{"duration":0.580498,"end_time":"2024-07-11T02:17:30.534138","exception":false,"start_time":"2024-07-11T02:17:29.95364","status":"completed"},"tags":[]},"outputs":[],"source":["# save the model\n","torch.save(decoder.state_dict(), \"./models/shakespeare_like_text_generator.pt\")"]},{"cell_type":"code","execution_count":27,"id":"fbc0ea8f","metadata":{"execution":{"iopub.execute_input":"2024-07-11T02:17:31.19386Z","iopub.status.busy":"2024-07-11T02:17:31.193476Z","iopub.status.idle":"2024-07-11T02:17:37.509762Z","shell.execute_reply":"2024-07-11T02:17:37.508793Z"},"papermill":{"duration":6.646206,"end_time":"2024-07-11T02:17:37.512059","exception":false,"start_time":"2024-07-11T02:17:30.865853","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["xoationed your soled that would within\n","To action a pitcheon, whom your mother silence!\n","\n","BIANCA.\n","\n","PETRUCHIO:\n","The shall be thee end forgot you that said:\n","You shall with all will in bring in Hereford.\n","\n","BARNIA:\n","Comess me thee, gentlement, general,\n","Alas, make my apping you? \n","FRIAR LA:\n","My grant sheet cut not shut\n","I not forg t\n","\n","\n"]}],"source":["n_embd = 784\n","vocab_size = len(vocab)\n","context_size = 128 # same as previously set\n","num_sa_heads = 16\n","sa_head_size = 64\n","\n","test_model = Decoder(vocab_size=vocab_size, n_embd=n_embd, context_size=context_size, num_sa_heads=num_sa_heads, sa_head_size=sa_head_size)\n","\n","test_model.load_state_dict(torch.load(\"./models/shakespeare_like_text_generator.pt\"))\n","test_model_generator = model_generator(model=test_model, max_length=320, num_samples=1, vocab_size=vocab_size) \n","test_model_generator.generate()\n","test_model_generator.print_outputs()\n"]},{"cell_type":"code","execution_count":null,"id":"26602d3f","metadata":{"papermill":{"duration":0.327546,"end_time":"2024-07-11T02:17:38.169662","exception":false,"start_time":"2024-07-11T02:17:37.842116","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5339176,"sourceId":8871363,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":1085.319632,"end_time":"2024-07-11T02:17:39.921164","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-11T01:59:34.601532","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}