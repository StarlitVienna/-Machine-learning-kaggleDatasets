{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/evelynartoria/decoder-transformer-model-from-scratch-pytorch?scriptVersionId=187728602\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"6408aa09","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:04.117137Z","iopub.status.busy":"2024-07-10T23:11:04.116817Z","iopub.status.idle":"2024-07-10T23:11:05.110121Z","shell.execute_reply":"2024-07-10T23:11:05.109071Z"},"papermill":{"duration":1.004865,"end_time":"2024-07-10T23:11:05.112535","exception":false,"start_time":"2024-07-10T23:11:04.10767","status":"completed"},"tags":[]},"outputs":[],"source":["!mkdir ./models"]},{"cell_type":"code","execution_count":2,"id":"90b29d53","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:05.128919Z","iopub.status.busy":"2024-07-10T23:11:05.128617Z","iopub.status.idle":"2024-07-10T23:11:08.518303Z","shell.execute_reply":"2024-07-10T23:11:08.516515Z"},"papermill":{"duration":3.401354,"end_time":"2024-07-10T23:11:08.521604","exception":false,"start_time":"2024-07-10T23:11:05.12025","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":3,"id":"3bf8fcb1","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:08.544755Z","iopub.status.busy":"2024-07-10T23:11:08.544201Z","iopub.status.idle":"2024-07-10T23:11:08.626004Z","shell.execute_reply":"2024-07-10T23:11:08.625013Z"},"papermill":{"duration":0.095716,"end_time":"2024-07-10T23:11:08.628016","exception":false,"start_time":"2024-07-10T23:11:08.5323","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["default device set to cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","generator = torch.Generator(device=device)\n","torch.set_default_device(device)\n","print(f\"default device set to {device}\")"]},{"cell_type":"code","execution_count":4,"id":"0f59a84d","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:08.647319Z","iopub.status.busy":"2024-07-10T23:11:08.646973Z","iopub.status.idle":"2024-07-10T23:11:08.669873Z","shell.execute_reply":"2024-07-10T23:11:08.66916Z"},"papermill":{"duration":0.036025,"end_time":"2024-07-10T23:11:08.671805","exception":false,"start_time":"2024-07-10T23:11:08.63578","status":"completed"},"tags":[]},"outputs":[],"source":["with open(\"/kaggle/input/shakespeare/input.txt\", 'r', encoding=\"utf-8\") as f:\n","    text = f.read()"]},{"cell_type":"code","execution_count":5,"id":"cf35e1f4","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:08.688057Z","iopub.status.busy":"2024-07-10T23:11:08.687784Z","iopub.status.idle":"2024-07-10T23:11:08.710641Z","shell.execute_reply":"2024-07-10T23:11:08.70992Z"},"papermill":{"duration":0.033008,"end_time":"2024-07-10T23:11:08.712441","exception":false,"start_time":"2024-07-10T23:11:08.679433","status":"completed"},"tags":[]},"outputs":[],"source":["vocab = sorted(set(text))\n","vocab_size = len(vocab)"]},{"cell_type":"code","execution_count":6,"id":"f5914bee","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:08.728133Z","iopub.status.busy":"2024-07-10T23:11:08.727863Z","iopub.status.idle":"2024-07-10T23:11:08.73742Z","shell.execute_reply":"2024-07-10T23:11:08.733061Z"},"papermill":{"duration":0.020332,"end_time":"2024-07-10T23:11:08.740105","exception":false,"start_time":"2024-07-10T23:11:08.719773","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["46\n","h\n"]}],"source":["stoi = {c: v for v, c in enumerate(vocab)}\n","itos = {v: c for c, v in stoi.items()}\n","\n","print(stoi[\"h\"])\n","print(itos[46])"]},{"cell_type":"code","execution_count":7,"id":"53d33c61","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:08.758857Z","iopub.status.busy":"2024-07-10T23:11:08.758286Z","iopub.status.idle":"2024-07-10T23:11:08.764135Z","shell.execute_reply":"2024-07-10T23:11:08.763234Z"},"papermill":{"duration":0.017493,"end_time":"2024-07-10T23:11:08.766291","exception":false,"start_time":"2024-07-10T23:11:08.748798","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[46, 43, 50, 50, 53, 1, 46, 53, 61, 1, 39, 56, 43, 1, 63, 53, 59, 12] hello how are you?\n"]}],"source":["encode = lambda e: [stoi[ch] for ch in e]\n","decode = lambda d: \"\".join([itos[idx] for idx in d])\n","\n","encoded = encode(\"hello how are you?\")\n","decoded = decode(encoded)\n","\n","print(encoded, decoded)"]},{"cell_type":"code","execution_count":8,"id":"0e72a1b6","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:08.782722Z","iopub.status.busy":"2024-07-10T23:11:08.782161Z","iopub.status.idle":"2024-07-10T23:11:09.104246Z","shell.execute_reply":"2024-07-10T23:11:09.103327Z"},"papermill":{"duration":0.332989,"end_time":"2024-07-10T23:11:09.10674","exception":false,"start_time":"2024-07-10T23:11:08.773751","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 256, 7168, 2560, 6272, 6784, 1152, 7296, 1536, 4864, 4480, 9856, 6144,\n","         128, 9728, 2176, 9344, 8576, 5632, 8960, 9216, 6656, 4736, 3072, 5120,\n","         640, 1408, 5248, 6400, 8448, 3584,  384, 4992,  896, 6528, 2432, 7936,\n","        6016, 2048, 3456, 7808, 6912, 4608, 9600, 3840, 4224, 1920, 2944, 5888,\n","        2688, 1280,    0, 2816, 3968, 8192, 1792, 5504, 8704, 7040, 8320, 5376,\n","        4096, 3200, 5760, 9088, 2304, 7424, 1664, 3712, 9472, 7552, 3328, 8064,\n","        7680,  512,  768, 8832, 4352, 1024], device='cuda:0')\n"]}],"source":["context_size = 128\n","random_idx_tensor = torch.randperm(10000//context_size) * context_size\n","print(random_idx_tensor)"]},{"cell_type":"code","execution_count":9,"id":"19be1044","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:09.124634Z","iopub.status.busy":"2024-07-10T23:11:09.124323Z","iopub.status.idle":"2024-07-10T23:11:09.130592Z","shell.execute_reply":"2024-07-10T23:11:09.129598Z"},"papermill":{"duration":0.017726,"end_time":"2024-07-10T23:11:09.13243","exception":false,"start_time":"2024-07-10T23:11:09.114704","status":"completed"},"tags":[]},"outputs":[],"source":["def make_dataset(data):\n","    random_idx_tensor = torch.randperm((len(data)-context_size)//context_size) * context_size\n","    inputs = torch.stack([data[idx:idx+context_size] for idx in random_idx_tensor])\n","    labels = torch.stack([data[idx+1:idx+context_size+1] for idx in random_idx_tensor])\n","    \n","    return TensorDataset(inputs.to(torch.long), labels.to(torch.long))"]},{"cell_type":"code","execution_count":10,"id":"39073004","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:09.148565Z","iopub.status.busy":"2024-07-10T23:11:09.148284Z","iopub.status.idle":"2024-07-10T23:11:10.988098Z","shell.execute_reply":"2024-07-10T23:11:10.986782Z"},"papermill":{"duration":1.850581,"end_time":"2024-07-10T23:11:10.990522","exception":false,"start_time":"2024-07-10T23:11:09.139941","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([56, 42, 57,  6,  1, 61, 46, 43, 52,  1, 63, 53, 59,  1, 57, 46, 39, 50,\n","        50,  1, 49, 52, 53, 61,  7,  7, 39, 57,  1, 47, 52,  1, 58, 46, 47, 57,\n","         1, 56, 39, 45, 43,  6,  0, 28, 56, 53, 60, 53, 49, 43, 42,  1, 40, 63,\n","         1, 46, 47, 51,  6,  1, 63, 53, 59,  1, 41, 39, 52, 52, 53, 58,  7,  7,\n","        58, 46, 43,  1, 45, 56, 43, 39, 58,  1, 42, 39, 52, 45, 43, 56,  0, 35,\n","        46, 47, 41, 46,  1, 58, 46, 47, 57,  1, 51, 39, 52,  5, 57,  1, 50, 47,\n","        44, 43,  1, 42, 47, 42,  1, 53, 61, 43,  1, 63, 53, 59,  6,  1, 63, 53,\n","        59,  5], device='cuda:0')\n","tensor([42, 57,  6,  1, 61, 46, 43, 52,  1, 63, 53, 59,  1, 57, 46, 39, 50, 50,\n","         1, 49, 52, 53, 61,  7,  7, 39, 57,  1, 47, 52,  1, 58, 46, 47, 57,  1,\n","        56, 39, 45, 43,  6,  0, 28, 56, 53, 60, 53, 49, 43, 42,  1, 40, 63,  1,\n","        46, 47, 51,  6,  1, 63, 53, 59,  1, 41, 39, 52, 52, 53, 58,  7,  7, 58,\n","        46, 43,  1, 45, 56, 43, 39, 58,  1, 42, 39, 52, 45, 43, 56,  0, 35, 46,\n","        47, 41, 46,  1, 58, 46, 47, 57,  1, 51, 39, 52,  5, 57,  1, 50, 47, 44,\n","        43,  1, 42, 47, 42,  1, 53, 61, 43,  1, 63, 53, 59,  6,  1, 63, 53, 59,\n","         5, 50], device='cuda:0')\n","dataset length --> 8713 (1115264 characters), that is, about the length of text 1115394 - context_size --> 1115266\n"]}],"source":["data = torch.tensor(encode(text))\n","dataset = make_dataset(data=data)\n","sample_input = dataset[0][0]\n","sample_label = dataset[0][1]\n","\n","print(sample_input)\n","print(sample_label)\n","\n","print(f\"dataset length --> {len(dataset)} ({len(dataset) * context_size} characters), that is, about the length of text {len(text)} - context_size --> {len(text)-context_size}\")"]},{"cell_type":"code","execution_count":11,"id":"a5b95cd8","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:11.008738Z","iopub.status.busy":"2024-07-10T23:11:11.007832Z","iopub.status.idle":"2024-07-10T23:11:11.015254Z","shell.execute_reply":"2024-07-10T23:11:11.014356Z"},"papermill":{"duration":0.018352,"end_time":"2024-07-10T23:11:11.017272","exception":false,"start_time":"2024-07-10T23:11:10.99892","status":"completed"},"tags":[]},"outputs":[],"source":["train_split = int(len(dataset)*0.75)\n","test_split = int(len(dataset)-train_split)\n","\n","train_dataset, test_dataset = random_split(dataset=dataset, lengths=[train_split, test_split], generator=generator)"]},{"cell_type":"code","execution_count":12,"id":"76bf4bcc","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:11.033946Z","iopub.status.busy":"2024-07-10T23:11:11.033676Z","iopub.status.idle":"2024-07-10T23:11:11.038447Z","shell.execute_reply":"2024-07-10T23:11:11.037611Z"},"papermill":{"duration":0.015209,"end_time":"2024-07-10T23:11:11.040394","exception":false,"start_time":"2024-07-10T23:11:11.025185","status":"completed"},"tags":[]},"outputs":[],"source":["batch_size = 32\n","train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, generator=generator)\n","test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, generator=generator)"]},{"cell_type":"code","execution_count":13,"id":"a75a910d","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:11.05732Z","iopub.status.busy":"2024-07-10T23:11:11.056777Z","iopub.status.idle":"2024-07-10T23:11:11.065407Z","shell.execute_reply":"2024-07-10T23:11:11.064581Z"},"papermill":{"duration":0.019192,"end_time":"2024-07-10T23:11:11.067275","exception":false,"start_time":"2024-07-10T23:11:11.048083","status":"completed"},"tags":[]},"outputs":[],"source":["class Head(nn.Module):\n","    def __init__(self, n_embd, head_size, context_size):\n","        super(Head, self).__init__()\n","        \n","        self.Q = nn.Linear(in_features=n_embd, out_features=head_size) # takes in BxTxC and return BxTxHead_size\n","        self.K = nn.Linear(in_features=n_embd, out_features=head_size)\n","        self.V = nn.Linear(in_features=n_embd, out_features=head_size)\n","        \n","        self.register_buffer(\"tril\", torch.tril(torch.ones(size=(context_size, context_size))))\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        B, T, C = x.shape # batch_size by context_size by n_embd\n","        q = self.Q(x) # BxTxHead_size\n","        k = self.K(x) # BxTxHead_size\n","        \n","        wei = q @ k.transpose(-2, -1) * (C ** -0.5) # BxTxHead_size @ BxHead_sizexT --> BxTxT then divided by the square root of n_embd\n","        \n","        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # :T and :T is needed in case context is smaller than context_size\n","        wei = torch.softmax(wei, dim=-1)\n","        v = self.V(x) # BxTxHead_size\n","        output = wei @ v # BxTxT @ BxTxHead_size --> BxTxHead_size\n","        \n","        return output"]},{"cell_type":"code","execution_count":14,"id":"5bcf6b83","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:11.083728Z","iopub.status.busy":"2024-07-10T23:11:11.083284Z","iopub.status.idle":"2024-07-10T23:11:11.089798Z","shell.execute_reply":"2024-07-10T23:11:11.088985Z"},"papermill":{"duration":0.016934,"end_time":"2024-07-10T23:11:11.091761","exception":false,"start_time":"2024-07-10T23:11:11.074827","status":"completed"},"tags":[]},"outputs":[],"source":["class MultiHeadedAttention(nn.Module):\n","    def __init__(self, n_embd, context_size, n_heads, head_size):\n","        super(MultiHeadedAttention, self).__init__()\n","        self.heads = nn.ModuleList([Head(n_embd=n_embd, head_size=head_size, context_size=context_size) for _ in range(n_heads)]) # BxTx (n_heads * head_size)\n","        self.projection = nn.Linear(in_features=n_heads*head_size, out_features=n_embd) # ensures the output is going to be o shape BxTxn_embd (BxTxC) so that is can go through multiple attention block\n","        \n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = torch.cat([head(x) for head in self.heads], dim=-1) # cat in the Channels dimension; output shape is BxTx (n_heads * head_size)\n","        x = self.projection(x)\n","        return  x"]},{"cell_type":"code","execution_count":15,"id":"1fa16a21","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:11.107974Z","iopub.status.busy":"2024-07-10T23:11:11.107712Z","iopub.status.idle":"2024-07-10T23:11:11.113384Z","shell.execute_reply":"2024-07-10T23:11:11.112511Z"},"papermill":{"duration":0.015853,"end_time":"2024-07-10T23:11:11.115193","exception":false,"start_time":"2024-07-10T23:11:11.09934","status":"completed"},"tags":[]},"outputs":[],"source":["class FeedForward(nn.Module):\n","    def __init__(self, in_features):\n","        super(FeedForward, self).__init__()\n","        self.ffwrd_layer = nn.Sequential(\n","            nn.Linear(in_features=in_features, out_features=in_features * 4), # scale by 4, according to the attention is all you need paper\n","            nn.ReLU(),\n","            nn.Linear(in_features=in_features * 4, out_features=in_features) # another projection layer\n","        )\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        return self.ffwrd_layer(x)"]},{"cell_type":"code","execution_count":16,"id":"e5a251a2","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:11.131615Z","iopub.status.busy":"2024-07-10T23:11:11.131343Z","iopub.status.idle":"2024-07-10T23:11:11.137718Z","shell.execute_reply":"2024-07-10T23:11:11.13689Z"},"papermill":{"duration":0.016896,"end_time":"2024-07-10T23:11:11.13967","exception":false,"start_time":"2024-07-10T23:11:11.122774","status":"completed"},"tags":[]},"outputs":[],"source":["class Block(nn.Module):\n","    def __init__(self, n_heads, head_size, n_embd, context_size):\n","        super(Block, self).__init__()\n","        self.multiheaded_self_attetion = MultiHeadedAttention(n_embd=n_embd, context_size=context_size, n_heads=n_heads, head_size=head_size) # create a multiheaded attention block; returns shape BxTx (num_heads*head_size)\n","        self.ffwrd = FeedForward(in_features=n_embd)\n","        self.layer_norm1 = nn.LayerNorm(n_embd)\n","        self.layer_norm2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = x + self.multiheaded_self_attetion(self.layer_norm1(x))\n","        x = x + self.ffwrd(self.layer_norm2(x))\n","\n","        return x"]},{"cell_type":"code","execution_count":17,"id":"df5ce6ff","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:11.156255Z","iopub.status.busy":"2024-07-10T23:11:11.155973Z","iopub.status.idle":"2024-07-10T23:11:11.168849Z","shell.execute_reply":"2024-07-10T23:11:11.167994Z"},"papermill":{"duration":0.023469,"end_time":"2024-07-10T23:11:11.170834","exception":false,"start_time":"2024-07-10T23:11:11.147365","status":"completed"},"tags":[]},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, n_embd, context_size, vocab_size, num_sa_heads, sa_head_size):\n","        super().__init__()\n","        \n","        self.vocab_size = vocab_size\n","        self.context_size = context_size\n","        self.n_embd = n_embd\n","        \n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # each character from the vocab has n_embd values associated to it\n","        self.positional_embedding_table = nn.Embedding(context_size, n_embd) # each character position in the context has n_embd values associated to it\n","        \n","        self.attention_blocks = nn.Sequential(\n","            Block(n_heads=num_sa_heads, head_size=sa_head_size, context_size=self.context_size, n_embd=self.n_embd), # takes in BxTxC, calculate logits of BxTx (num_heads * head_size), then project it as BxTxC\n","            Block(n_heads=num_sa_heads, head_size=sa_head_size, context_size=self.context_size, n_embd=self.n_embd),\n","            Block(n_heads=num_sa_heads, head_size=sa_head_size, context_size=self.context_size, n_embd=self.n_embd),\n","            nn.LayerNorm(n_embd) # normalize the layers\n","        )\n","        \n","\n","        self.lm_head = nn.Linear(in_features=n_embd, out_features=vocab_size) # (B, T, vocab_size)\n","        \n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        B, T = x.shape # batch_size and context_size\n","        positions = torch.arange(start=0, end=T, step=1)\n","        \n","        pos_emb = self.positional_embedding_table(positions) # T x C --> in broadcasting, pytorch adds a batch dim=1\n","        token_emb = self.token_embedding_table(x) # B x T x C\n","        \n","        x = token_emb + pos_emb # BxTxC\n","        x = self.attention_blocks(x) # returns logits of shape BxTx (self.sa_head_size * self.num_sa_heads) projected to BxTxC\n","        x = self.lm_head(x) # BxTxvocab_size --> BxTxHead_size @ BxTxVocab_size return BxTxVocab_size\n","\n","        return x.view(B*T, self.vocab_size) # easier shape to work with the labels\n","    \n","    def generate(self, starting_idx: torch.Tensor, max_length: int, debug: bool) -> torch.Tensor:\n","        full_text = decode([starting_idx.item()])\n","        context = starting_idx\n","        \n","        for _ in range(max_length):\n","            context = context[:, -self.context_size:] # make sure the context is of size context_size\n","            \n","            if debug:\n","                print(f\"predicting on context: {decode(context[0].tolist())}\")\n","            \n","            logits = self(context) # B*T x vocab_size --> 1*2 x vocab_size\n","            logits = logits[-1, :].view(1, self.vocab_size) # only take the prediction for the last character\n","            percents = torch.softmax(logits, dim=1) # 1*2xvocab_size\n","            pred = torch.multinomial(percents, num_samples=1) \n","            full_text += decode(pred.tolist()[0])\n","            context = torch.cat([context, pred], dim=1) # add to the context dimension instead of the batch dim\n","            \n","        return full_text\n"]},{"cell_type":"code","execution_count":18,"id":"94ce383f","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:11.187459Z","iopub.status.busy":"2024-07-10T23:11:11.187216Z","iopub.status.idle":"2024-07-10T23:11:11.198999Z","shell.execute_reply":"2024-07-10T23:11:11.198337Z"},"papermill":{"duration":0.022147,"end_time":"2024-07-10T23:11:11.200792","exception":false,"start_time":"2024-07-10T23:11:11.178645","status":"completed"},"tags":[]},"outputs":[],"source":["class model_generator:\n","    def __init__(self, model: object, max_length: int, num_samples: int, vocab_size: int):\n","        self.model = model\n","        self.max_length = max_length\n","        self.num_samples = num_samples\n","        self.vocab_size = vocab_size\n","        \n","        self.last_output = \"\"\n","        \n","        self.params_dict = {\n","            \"model\": model,\n","            \"max_length\": max_length,\n","            \"num_samples\": num_samples,\n","            \"previous_outputs\": []\n","        }\n","    \n","    @torch.no_grad\n","    def generate(self, starting_char: str = None, clear_outputs: bool = True, debug: bool = False):\n","        self.model.eval()\n","        \n","        if clear_outputs:\n","            self.clear_ouptuts()\n","            \n","        if starting_char is None:\n","            starting_char = decode([torch.randint(0, vocab_size, (1,)).item()])\n","            \n","        for _ in range(self.num_samples):\n","            starting_idx = torch.tensor(encode(starting_char), dtype=torch.long).view(1, 1)\n","            output = self.model.generate(starting_idx=starting_idx, max_length=self.max_length, debug=debug)\n","            self.params_dict[\"previous_outputs\"].append(output)\n","            self.last_output = output\n","    \n","    def update_params(self, model: object = None, max_length: int = None, num_samples: int = None, clear_outputs: bool = None):\n","        if clear_outputs:\n","            self.clear_outputs()\n","            \n","        updated_dict = {\n","            \"model\": model,\n","            \"max_length\": max_length,\n","            \"num_samples\": num_samples\n","        }\n","        \n","        for attribute, value in updated_dict.items():\n","            if value is not None:\n","                self.params_dict[attribute] = value\n","                setattr(self, attribute, value)\n","    \n","    def clear_ouptuts(self):\n","        self.params_dict[\"previous_outputs\"] = []\n","        self.last_output = \"\"\n","        \n","    def print_outputs(self, last: bool = None):\n","        if last:\n","            print(self.last_output)\n","        else:\n","            for output in self.params_dict[\"previous_outputs\"]:\n","                print(f\"{output}\\n\\n\")"]},{"cell_type":"code","execution_count":19,"id":"13a44019","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:11.217839Z","iopub.status.busy":"2024-07-10T23:11:11.217004Z","iopub.status.idle":"2024-07-10T23:11:12.639056Z","shell.execute_reply":"2024-07-10T23:11:12.638061Z"},"papermill":{"duration":1.43304,"end_time":"2024-07-10T23:11:12.641519","exception":false,"start_time":"2024-07-10T23:11:11.208479","status":"completed"},"tags":[]},"outputs":[],"source":["n_embd = 784\n","vocab_size = len(vocab)\n","context_size = 128 # same as previously set\n","num_sa_heads = 16\n","sa_head_size = 64\n","\n","decoder = Decoder(vocab_size=vocab_size, n_embd=n_embd, context_size=context_size, num_sa_heads=num_sa_heads, sa_head_size=sa_head_size)\n","optimizer = torch.optim.Adam(params=decoder.parameters(), lr=1e-3)\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":20,"id":"ae6b24f9","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:12.658949Z","iopub.status.busy":"2024-07-10T23:11:12.658564Z","iopub.status.idle":"2024-07-10T23:11:12.662903Z","shell.execute_reply":"2024-07-10T23:11:12.662037Z"},"papermill":{"duration":0.015092,"end_time":"2024-07-10T23:11:12.664885","exception":false,"start_time":"2024-07-10T23:11:12.649793","status":"completed"},"tags":[]},"outputs":[],"source":["decoder_generator = model_generator(model=decoder, max_length=32, num_samples=1, vocab_size=vocab_size)"]},{"cell_type":"code","execution_count":21,"id":"0a73570b","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:12.681578Z","iopub.status.busy":"2024-07-10T23:11:12.681327Z","iopub.status.idle":"2024-07-10T23:11:13.732748Z","shell.execute_reply":"2024-07-10T23:11:13.731572Z"},"papermill":{"duration":1.062637,"end_time":"2024-07-10T23:11:13.735278","exception":false,"start_time":"2024-07-10T23:11:12.672641","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["RcJq!rTUw:RyhyBp$L ucAUg;K!qFB,N&\n","\n","\n"]}],"source":["#decoder_generator.update_params(max_length=100, num_samples=1)\n","decoder_generator.generate()\n","decoder_generator.print_outputs()"]},{"cell_type":"code","execution_count":22,"id":"c8954218","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:13.752674Z","iopub.status.busy":"2024-07-10T23:11:13.752385Z","iopub.status.idle":"2024-07-10T23:11:13.933717Z","shell.execute_reply":"2024-07-10T23:11:13.932631Z"},"papermill":{"duration":0.192233,"end_time":"2024-07-10T23:11:13.935852","exception":false,"start_time":"2024-07-10T23:11:13.743619","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(4.3892, device='cuda:0')\n"]}],"source":["decoder.eval()\n","test_loss_fn = nn.CrossEntropyLoss()\n","batch_sample_inputs, batch_sample_labels = next(iter(train_dataloader))\n","with torch.inference_mode():\n","    #print(batch_sample_inputs)\n","    #print(batch_sample_labels)\n","    logits = decoder(batch_sample_inputs)\n","    labels = batch_sample_labels.view(-1) # turns the label shape into a B*T\n","    #print(logits) # 4 batches of 8 characters each, the model is trying to predict the next sequence\n","    #print(labels)\n","    loss = test_loss_fn(logits, batch_sample_labels.view(-1))\n","    print(loss)"]},{"cell_type":"code","execution_count":23,"id":"dfc433e0","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:13.953623Z","iopub.status.busy":"2024-07-10T23:11:13.953331Z","iopub.status.idle":"2024-07-10T23:11:13.959122Z","shell.execute_reply":"2024-07-10T23:11:13.958345Z"},"papermill":{"duration":0.016716,"end_time":"2024-07-10T23:11:13.960975","exception":false,"start_time":"2024-07-10T23:11:13.944259","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model(model, dataloader, loss_fn, optimizer, epochs):\n","    model.train()\n","    \n","    for epoch in range(epochs):\n","        for batch, (X, y) in tqdm(enumerate(dataloader)):\n","            logits = model(X) # shape of B*T x vocab_size\n","            labels = y.view(-1) # shape of B*T --> each character has it's own prediction\n","            loss = loss_fn(logits, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            if batch % 100 == 0:\n","                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")"]},{"cell_type":"code","execution_count":24,"id":"e7787235","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:11:13.97779Z","iopub.status.busy":"2024-07-10T23:11:13.977519Z","iopub.status.idle":"2024-07-10T23:28:25.830458Z","shell.execute_reply":"2024-07-10T23:28:25.82943Z"},"papermill":{"duration":1031.863807,"end_time":"2024-07-10T23:28:25.832735","exception":false,"start_time":"2024-07-10T23:11:13.968928","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["1it [00:00,  2.52it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 4.394429683685303 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:23,  4.19it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 2.4578640460968018 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:48,  4.08it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 2.235759735107422 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:48,  4.19it/s]\n","1it [00:00,  4.07it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 2.2955939769744873 at epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.91it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 2.000166177749634 at epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:51,  3.90it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.7390151023864746 at epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.95it/s]\n","1it [00:00,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.771932601928711 at epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.700164556503296 at epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.6728771924972534 at epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.97it/s]\n","1it [00:00,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.5364112854003906 at epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.91it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.5434497594833374 at epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:51,  3.92it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.586573600769043 at epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.94it/s]\n","1it [00:00,  3.93it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.4715495109558105 at epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.5315405130386353 at epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:51,  3.91it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.4816144704818726 at epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.95it/s]\n","1it [00:00,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.3621184825897217 at epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.93it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.4543262720108032 at epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:51,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.4408073425292969 at epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.95it/s]\n","1it [00:00,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.3393572568893433 at epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.3958181142807007 at epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.93it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.3905450105667114 at epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.96it/s]\n","1it [00:00,  4.05it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.2626875638961792 at epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.3121176958084106 at epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.3210190534591675 at epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.96it/s]\n","1it [00:00,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.2767424583435059 at epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.2819160223007202 at epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.2620248794555664 at epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.96it/s]\n","1it [00:00,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.1620242595672607 at epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.1902016401290894 at epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.92it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.2189648151397705 at epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.96it/s]\n","1it [00:00,  4.00it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.0956398248672485 at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.92it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.1308989524841309 at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.93it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.2420809268951416 at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.96it/s]\n","1it [00:00,  3.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.0267654657363892 at epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.93it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.097220778465271 at epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.1269652843475342 at epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.96it/s]\n","1it [00:00,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.9361605048179626 at epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.93it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.0088902711868286 at epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.1004530191421509 at epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.96it/s]\n","1it [00:00,  3.98it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.8747413158416748 at epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.9314310550689697 at epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.9656411409378052 at epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.97it/s]\n","1it [00:00,  3.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.7812402248382568 at epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.8872048854827881 at epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.8955422043800354 at epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.97it/s]\n","1it [00:00,  3.89it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.7058507204055786 at epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.7878478169441223 at epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.8347071409225464 at epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.97it/s]\n","1it [00:00,  3.90it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.5803107619285583 at epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.6996538639068604 at epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.7376101613044739 at epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.96it/s]\n","1it [00:00,  4.00it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.4922633767127991 at epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.5820157527923584 at epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.6707831025123596 at epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.98it/s]\n","1it [00:00,  3.98it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.4281761348247528 at epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.5230690240859985 at epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.5732739567756653 at epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.97it/s]\n","1it [00:00,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.3629069924354553 at epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:25,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.4555146396160126 at epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["201it [00:50,  3.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.49032214283943176 at epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:51,  3.97it/s]\n"]}],"source":["train_model(model=decoder, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, epochs=20)"]},{"cell_type":"code","execution_count":25,"id":"02fcdb0f","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:28:26.500847Z","iopub.status.busy":"2024-07-10T23:28:26.500005Z","iopub.status.idle":"2024-07-10T23:29:14.269168Z","shell.execute_reply":"2024-07-10T23:29:14.268191Z"},"papermill":{"duration":48.445985,"end_time":"2024-07-10T23:29:14.6174","exception":false,"start_time":"2024-07-10T23:28:26.171415","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["generating 5 sample of 500 characters each\n","y to this of rance,\n","Take the rose of it of our leade. Now, weak, it ever\n","For I have to me, that continue it now\n","He thus smay's to be to contine; and he, more play, sir,\n","He was thee to Rome, here strongly this roam;\n","I will come to this come to her:\n","Nay, or be there.\n","\n","MERCUTITUS:\n","I hought or well tell me.\n","\n","CORIONAS:\n","A noble lamb thought something was to me\n","doth us; but the fow of that 'tis so dazen.\n","\n","SICINIWSCe:\n","Let'l not me:\n","Nay, be the oath! what with absence: I wannot do't,\n","What nay, hads, been \n","\n","\n","y brother, forth thee,\n","What defenderstands sulment to swear John.\n","Three, come, know, by Saint Planta! Whither blest!\n","But plucky, gently, with a fatal holy--\n","Stray of Capulet hath\n","And be tour that an enemy!\n","\n","GREMIO:\n","So this temper.\n","\n","GLOUCESTER:\n","\n","BUCH:\n","Nay, with you not what?\n","\n","ISABELLA:\n","What's a methort?\n","\n","ARINCELO:\n","Sweet or wear no!\n","\n","ANGELO:\n","He hath and all it?\n","\n","ISABELLA:\n","Grandam, hand not to seen the eaus is worth\n","an excellen of that traitor.\n","\n","ISABELLA:\n","O do! what's the manner?\n","\n","LUCENTIO:\n","O doth i\n","\n","\n","y met, my lady;\n","Weith many moralislyman countes for them.\n","\n","TRANIO:\n","I told go to the most inward the fight\n","to the joing.\n","\n","BENVOLIOLIO:\n","Calude up!\n","\n","GREMIO:\n","Ap. he thus will tell 'tis our traitors:\n","Thus both some put of York,\n","And I hear hold take to thee rich lent,\n","Thou canst give me as me, or I too say:\n","But with me, 'tis like a little gland.\n","Come, crance!\n","A bans! Warm no ance of our wooth!\n","Const unsit not the roon,\n","Afternoon, of word by curt of this: and you,\n","When at said, but rather advance, we la\n","\n","\n","y great she shall be married his most\n","Against the all.\n","Let me comfort, and I mean throw more stoop\n","So fair of her faultinate! rans you renough;or\n","Thou shalt to be so smelt ortune of life,\n","Which I must consule hear the boats.\n","\n","CORIOLANUS:\n","No, never; for it that that the will they\n","wave made thee, I hold not light lie. Yet told\n","Now thee say a vice to beat the world. If thou leave\n","in the gods-conting that lies--wit not something sun.\n","\n","ISABELLA:\n","What, he will't were a forch charge\n","ballious lastings ?\n","\n","\n","\n","ya, therefore enforces the maids,\n","Biond the humour of thine: Overy danger\n","Upon the millous; life of hears, but is well,\n","For that went to make a stonemen content\n","Where man at such dooms. Seem for you.\n","\n","BRINAND:\n","What, what's you fals, give me speaking?\n","\n","PETRUMIO:\n","Nay, good all against us?\n","\n","SICINIUS:\n","No, I will well.\n","\n","BRUTUS:\n","No more of the beauty is heard.\n","\n","PRINCE:\n","The old good good devour! lay, Bone woo.\n","Would I wenty, fland this but of rage?\n","\n","RICHARD:\n","\n","GREMIONE:\n","Yea, fathere now, but that all tog\n","\n","\n"]}],"source":["print(\"generating 5 sample of 500 characters each\")\n","\n","decoder_generator.update_params(max_length=500, num_samples=5)\n","decoder_generator.generate()\n","decoder_generator.print_outputs()"]},{"cell_type":"markdown","id":"8410d013","metadata":{"papermill":{"duration":0.3283,"end_time":"2024-07-10T23:29:15.321885","exception":false,"start_time":"2024-07-10T23:29:14.993585","status":"completed"},"tags":[]},"source":["# Save and load the model"]},{"cell_type":"code","execution_count":26,"id":"c98bcb4e","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:29:15.978663Z","iopub.status.busy":"2024-07-10T23:29:15.977982Z","iopub.status.idle":"2024-07-10T23:29:16.175948Z","shell.execute_reply":"2024-07-10T23:29:16.175171Z"},"papermill":{"duration":0.53072,"end_time":"2024-07-10T23:29:16.178224","exception":false,"start_time":"2024-07-10T23:29:15.647504","status":"completed"},"tags":[]},"outputs":[],"source":["# save the model\n","torch.save(decoder.state_dict(), \"./models/shakespeare_like_text_generator.pt\")"]},{"cell_type":"code","execution_count":27,"id":"b359b249","metadata":{"execution":{"iopub.execute_input":"2024-07-10T23:29:16.834452Z","iopub.status.busy":"2024-07-10T23:29:16.833708Z","iopub.status.idle":"2024-07-10T23:29:23.049436Z","shell.execute_reply":"2024-07-10T23:29:23.048183Z"},"papermill":{"duration":6.543391,"end_time":"2024-07-10T23:29:23.051685","exception":false,"start_time":"2024-07-10T23:29:16.508294","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["& never the grost:\n","A man age that the bid you cannot joy\n","To greature of the face that God's all that guess\n","Which am untimely in all together:\n","Come, concluded to the meats,\n","If would be tumble-buried, with angled boy.\n","\n","CLIFFORD:\n","O, the gold!\n","I told Barest thou liest whereof that makest\n","Addest thou understance?\n","\n","PETRUCHIO:\n","\n","\n"]}],"source":["n_embd = 784\n","vocab_size = len(vocab)\n","context_size = 128 # same as previously set\n","num_sa_heads = 16\n","sa_head_size = 64\n","\n","test_model = Decoder(vocab_size=vocab_size, n_embd=n_embd, context_size=context_size, num_sa_heads=num_sa_heads, sa_head_size=sa_head_size)\n","\n","test_model.load_state_dict(torch.load(\"./models/shakespeare_like_text_generator.pt\"))\n","test_model_generator = model_generator(model=test_model, max_length=320, num_samples=1, vocab_size=vocab_size) \n","test_model_generator.generate()\n","test_model_generator.print_outputs()\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5339176,"sourceId":8871363,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":1103.029636,"end_time":"2024-07-10T23:29:24.509375","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-10T23:11:01.479739","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}