{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd0cf9a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:13.999709Z",
     "iopub.status.busy": "2024-07-08T18:04:13.998659Z",
     "iopub.status.idle": "2024-07-08T18:04:14.790039Z",
     "shell.execute_reply": "2024-07-08T18:04:14.788779Z"
    },
    "papermill": {
     "duration": 0.802563,
     "end_time": "2024-07-08T18:04:14.792616",
     "exception": false,
     "start_time": "2024-07-08T18:04:13.990053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/us-baby-names/StateNames.csv\n",
      "/kaggle/input/us-baby-names/NationalReadMe.pdf\n",
      "/kaggle/input/us-baby-names/hashes.txt\n",
      "/kaggle/input/us-baby-names/NationalNames.csv\n",
      "/kaggle/input/us-baby-names/StateReadMe.pdf\n",
      "/kaggle/input/us-baby-names/database.sqlite\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d94f7",
   "metadata": {
    "papermill": {
     "duration": 0.005948,
     "end_time": "2024-07-08T18:04:14.805435",
     "exception": false,
     "start_time": "2024-07-08T18:04:14.799487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "300922d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:14.819940Z",
     "iopub.status.busy": "2024-07-08T18:04:14.818928Z",
     "iopub.status.idle": "2024-07-08T18:04:17.997367Z",
     "shell.execute_reply": "2024-07-08T18:04:17.996512Z"
    },
    "papermill": {
     "duration": 3.188341,
     "end_time": "2024-07-08T18:04:17.999887",
     "exception": false,
     "start_time": "2024-07-08T18:04:14.811546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd00e8c3",
   "metadata": {
    "papermill": {
     "duration": 0.005501,
     "end_time": "2024-07-08T18:04:18.011831",
     "exception": false,
     "start_time": "2024-07-08T18:04:18.006330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "237ffc54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:18.025105Z",
     "iopub.status.busy": "2024-07-08T18:04:18.024621Z",
     "iopub.status.idle": "2024-07-08T18:04:18.031907Z",
     "shell.execute_reply": "2024-07-08T18:04:18.030802Z"
    },
    "papermill": {
     "duration": 0.016556,
     "end_time": "2024-07-08T18:04:18.033950",
     "exception": false,
     "start_time": "2024-07-08T18:04:18.017394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default device set to cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "generator = torch.Generator(device=device)\n",
    "print(f\"default device set to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9270a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:18.047482Z",
     "iopub.status.busy": "2024-07-08T18:04:18.047163Z",
     "iopub.status.idle": "2024-07-08T18:04:20.004526Z",
     "shell.execute_reply": "2024-07-08T18:04:20.003498Z"
    },
    "papermill": {
     "duration": 1.967083,
     "end_time": "2024-07-08T18:04:20.007173",
     "exception": false,
     "start_time": "2024-07-08T18:04:18.040090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mary</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>7065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Anna</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Emma</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Minnie</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825428</th>\n",
       "      <td>1825429</td>\n",
       "      <td>Zykeem</td>\n",
       "      <td>2014</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825429</th>\n",
       "      <td>1825430</td>\n",
       "      <td>Zymeer</td>\n",
       "      <td>2014</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825430</th>\n",
       "      <td>1825431</td>\n",
       "      <td>Zymiere</td>\n",
       "      <td>2014</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825431</th>\n",
       "      <td>1825432</td>\n",
       "      <td>Zyran</td>\n",
       "      <td>2014</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825432</th>\n",
       "      <td>1825433</td>\n",
       "      <td>Zyrin</td>\n",
       "      <td>2014</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1825433 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id       Name  Year Gender  Count\n",
       "0              1       Mary  1880      F   7065\n",
       "1              2       Anna  1880      F   2604\n",
       "2              3       Emma  1880      F   2003\n",
       "3              4  Elizabeth  1880      F   1939\n",
       "4              5     Minnie  1880      F   1746\n",
       "...          ...        ...   ...    ...    ...\n",
       "1825428  1825429     Zykeem  2014      M      5\n",
       "1825429  1825430     Zymeer  2014      M      5\n",
       "1825430  1825431    Zymiere  2014      M      5\n",
       "1825431  1825432      Zyran  2014      M      5\n",
       "1825432  1825433      Zyrin  2014      M      5\n",
       "\n",
       "[1825433 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_csv = pd.read_csv(\"/kaggle/input/us-baby-names/NationalNames.csv\")\n",
    "names_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab566ed",
   "metadata": {
    "papermill": {
     "duration": 0.007056,
     "end_time": "2024-07-08T18:04:20.021126",
     "exception": false,
     "start_time": "2024-07-08T18:04:20.014070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model hyperparameters\n",
    "- context_size --> how many characters the model look at before making a prediction\n",
    "- n_embd --> number of values per character token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63be0609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:20.035673Z",
     "iopub.status.busy": "2024-07-08T18:04:20.034957Z",
     "iopub.status.idle": "2024-07-08T18:04:20.540342Z",
     "shell.execute_reply": "2024-07-08T18:04:20.539229Z"
    },
    "papermill": {
     "duration": 0.515349,
     "end_time": "2024-07-08T18:04:20.542884",
     "exception": false,
     "start_time": "2024-07-08T18:04:20.027535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_size = 4\n",
    "n_embd = 5\n",
    "vocab = set(\"\".join(names_csv[\"Name\"]))\n",
    "vocab.add(\".\")\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6139c8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:20.557057Z",
     "iopub.status.busy": "2024-07-08T18:04:20.556691Z",
     "iopub.status.idle": "2024-07-08T18:04:20.562625Z",
     "shell.execute_reply": "2024-07-08T18:04:20.561591Z"
    },
    "papermill": {
     "duration": 0.015465,
     "end_time": "2024-07-08T18:04:20.564808",
     "exception": false,
     "start_time": "2024-07-08T18:04:20.549343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "l\n"
     ]
    }
   ],
   "source": [
    "stoi = {c: v for v, c in enumerate(vocab)}\n",
    "itos = {v: c for c, v in stoi.items()}\n",
    "print(stoi[\".\"])\n",
    "print(itos[39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d490ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:20.583966Z",
     "iopub.status.busy": "2024-07-08T18:04:20.582836Z",
     "iopub.status.idle": "2024-07-08T18:04:20.591347Z",
     "shell.execute_reply": "2024-07-08T18:04:20.590107Z"
    },
    "papermill": {
     "duration": 0.022457,
     "end_time": "2024-07-08T18:04:20.593684",
     "exception": false,
     "start_time": "2024-07-08T18:04:20.571227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dataset(data, context_size):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    context = [stoi[\".\"]] * context_size\n",
    "    for name in names_csv[\"Name\"]:\n",
    "        for ch in name:\n",
    "            inputs.append(context)\n",
    "            labels.append(stoi[ch])\n",
    "            context = context[1:] + [stoi[ch]]\n",
    "    \n",
    "    inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return TensorDataset(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7838fbeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:20.618005Z",
     "iopub.status.busy": "2024-07-08T18:04:20.614221Z",
     "iopub.status.idle": "2024-07-08T18:04:46.349572Z",
     "shell.execute_reply": "2024-07-08T18:04:46.348773Z"
    },
    "papermill": {
     "duration": 25.748441,
     "end_time": "2024-07-08T18:04:46.352402",
     "exception": false,
     "start_time": "2024-07-08T18:04:20.603961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = make_dataset(data=names_csv, context_size=context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b638ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:46.367924Z",
     "iopub.status.busy": "2024-07-08T18:04:46.367540Z",
     "iopub.status.idle": "2024-07-08T18:04:47.892112Z",
     "shell.execute_reply": "2024-07-08T18:04:47.891095Z"
    },
    "papermill": {
     "duration": 1.53533,
     "end_time": "2024-07-08T18:04:47.894745",
     "exception": false,
     "start_time": "2024-07-08T18:04:46.359415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_split = int(len(dataset) * 0.8)\n",
    "test_split = int(len(dataset) - train_split)\n",
    "train_dataset, test_dataset = random_split(dataset=dataset, lengths=[train_split, test_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb7b328",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:47.910086Z",
     "iopub.status.busy": "2024-07-08T18:04:47.909451Z",
     "iopub.status.idle": "2024-07-08T18:04:47.914762Z",
     "shell.execute_reply": "2024-07-08T18:04:47.913787Z"
    },
    "papermill": {
     "duration": 0.015496,
     "end_time": "2024-07-08T18:04:47.917152",
     "exception": false,
     "start_time": "2024-07-08T18:04:47.901656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, generator=generator)\n",
    "test_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b467ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:47.932955Z",
     "iopub.status.busy": "2024-07-08T18:04:47.932509Z",
     "iopub.status.idle": "2024-07-08T18:04:48.034869Z",
     "shell.execute_reply": "2024-07-08T18:04:48.033989Z"
    },
    "papermill": {
     "duration": 0.113061,
     "end_time": "2024-07-08T18:04:48.036996",
     "exception": false,
     "start_time": "2024-07-08T18:04:47.923935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, context_size, vocab_size, n_embd):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.context_size = context_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        \n",
    "        self.token_emb = nn.Embedding(vocab_size, n_embd) # B x T x C (B=batches; T=context_size, C=n_embd)\n",
    "        self.linear1 = nn.Linear(in_features=context_size*n_embd, out_features=8*8)\n",
    "        self.linear2 = nn.Linear(in_features=8*8, out_features=vocab_size)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.token_emb(x)\n",
    "        \n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T*C)\n",
    "        x = self.act_fn(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def generate_name(self, starting_char, max_length):\n",
    "        name = \"\"\n",
    "        last_char = starting_char\n",
    "        i = 0\n",
    "        while last_char != \".\" and i < max_length:\n",
    "            context = [stoi[\".\"]] * (self.context_size - 1) + [stoi[last_char]]\n",
    "            context = torch.tensor(context, dtype=torch.long).view(1, len(context))\n",
    "\n",
    "            logits = self(context)\n",
    "            percents = torch.softmax(logits, dim=1)\n",
    "            pred = torch.argmax(percents, dim=1)\n",
    "            \n",
    "            i += 1\n",
    "            name += itos[pred.item()]\n",
    "            last_char = itos[pred.item()]\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2634e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:48.051868Z",
     "iopub.status.busy": "2024-07-08T18:04:48.051132Z",
     "iopub.status.idle": "2024-07-08T18:04:49.507067Z",
     "shell.execute_reply": "2024-07-08T18:04:49.506102Z"
    },
    "papermill": {
     "duration": 1.465738,
     "end_time": "2024-07-08T18:04:49.509357",
     "exception": false,
     "start_time": "2024-07-08T18:04:48.043619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MLP(context_size=context_size, vocab_size=vocab_size, n_embd=n_embd)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa77a7c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:49.523954Z",
     "iopub.status.busy": "2024-07-08T18:04:49.523473Z",
     "iopub.status.idle": "2024-07-08T18:04:49.578407Z",
     "shell.execute_reply": "2024-07-08T18:04:49.577289Z"
    },
    "papermill": {
     "duration": 0.064635,
     "end_time": "2024-07-08T18:04:49.580634",
     "exception": false,
     "start_time": "2024-07-08T18:04:49.515999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppppp\n"
     ]
    }
   ],
   "source": [
    "print(model.generate_name(starting_char=\"L\", max_length=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce177319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:49.595376Z",
     "iopub.status.busy": "2024-07-08T18:04:49.595065Z",
     "iopub.status.idle": "2024-07-08T18:04:49.601166Z",
     "shell.execute_reply": "2024-07-08T18:04:49.600257Z"
    },
    "papermill": {
     "duration": 0.015699,
     "end_time": "2024-07-08T18:04:49.603145",
     "exception": false,
     "start_time": "2024-07-08T18:04:49.587446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, loss_fn, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch % 5000 == 0:\n",
    "                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")\n",
    "                \n",
    "    print(f\"loss for the very last batch --> {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78c0c8cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:04:49.616964Z",
     "iopub.status.busy": "2024-07-08T18:04:49.616642Z",
     "iopub.status.idle": "2024-07-08T18:08:19.066938Z",
     "shell.execute_reply": "2024-07-08T18:08:19.065866Z"
    },
    "papermill": {
     "duration": 209.459691,
     "end_time": "2024-07-08T18:08:19.069177",
     "exception": false,
     "start_time": "2024-07-08T18:04:49.609486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 0 --> 3.972154378890991 at epoch 0\n",
      "loss for batch 5000 --> 2.5103845596313477 at epoch 0\n",
      "loss for batch 10000 --> 2.5113413333892822 at epoch 0\n",
      "loss for batch 15000 --> 2.5604820251464844 at epoch 0\n",
      "loss for batch 20000 --> 2.5303328037261963 at epoch 0\n",
      "loss for batch 25000 --> 2.4202380180358887 at epoch 0\n",
      "loss for batch 30000 --> 2.459824323654175 at epoch 0\n",
      "loss for batch 35000 --> 2.4654221534729004 at epoch 0\n",
      "loss for batch 40000 --> 2.4578616619110107 at epoch 0\n",
      "loss for batch 45000 --> 2.5074100494384766 at epoch 0\n",
      "loss for batch 50000 --> 2.6247498989105225 at epoch 0\n",
      "loss for batch 55000 --> 2.4044110774993896 at epoch 0\n",
      "loss for batch 60000 --> 2.059835910797119 at epoch 0\n",
      "loss for batch 65000 --> 2.365466594696045 at epoch 0\n",
      "loss for batch 70000 --> 2.3092923164367676 at epoch 0\n",
      "loss for the very last batch --> 2.2834556102752686\n"
     ]
    }
   ],
   "source": [
    "train_model(model=model, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e39c3",
   "metadata": {
    "papermill": {
     "duration": 0.007451,
     "end_time": "2024-07-08T18:08:19.084597",
     "exception": false,
     "start_time": "2024-07-08T18:08:19.077146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 13,
     "sourceId": 7651,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 249.023035,
   "end_time": "2024-07-08T18:08:20.314841",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-08T18:04:11.291806",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
