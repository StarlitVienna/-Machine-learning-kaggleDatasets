{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd44ab2b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:41.870958Z",
     "iopub.status.busy": "2024-07-08T18:23:41.870537Z",
     "iopub.status.idle": "2024-07-08T18:23:42.733296Z",
     "shell.execute_reply": "2024-07-08T18:23:42.732050Z"
    },
    "papermill": {
     "duration": 0.873963,
     "end_time": "2024-07-08T18:23:42.736403",
     "exception": false,
     "start_time": "2024-07-08T18:23:41.862440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/us-baby-names/StateNames.csv\n",
      "/kaggle/input/us-baby-names/NationalReadMe.pdf\n",
      "/kaggle/input/us-baby-names/hashes.txt\n",
      "/kaggle/input/us-baby-names/NationalNames.csv\n",
      "/kaggle/input/us-baby-names/StateReadMe.pdf\n",
      "/kaggle/input/us-baby-names/database.sqlite\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6851da15",
   "metadata": {
    "papermill": {
     "duration": 0.005633,
     "end_time": "2024-07-08T18:23:42.748070",
     "exception": false,
     "start_time": "2024-07-08T18:23:42.742437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f55918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:42.761770Z",
     "iopub.status.busy": "2024-07-08T18:23:42.760822Z",
     "iopub.status.idle": "2024-07-08T18:23:46.141409Z",
     "shell.execute_reply": "2024-07-08T18:23:46.140323Z"
    },
    "papermill": {
     "duration": 3.390228,
     "end_time": "2024-07-08T18:23:46.144098",
     "exception": false,
     "start_time": "2024-07-08T18:23:42.753870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e3f654",
   "metadata": {
    "papermill": {
     "duration": 0.005517,
     "end_time": "2024-07-08T18:23:46.155776",
     "exception": false,
     "start_time": "2024-07-08T18:23:46.150259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834a8122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:46.169217Z",
     "iopub.status.busy": "2024-07-08T18:23:46.168684Z",
     "iopub.status.idle": "2024-07-08T18:23:46.176862Z",
     "shell.execute_reply": "2024-07-08T18:23:46.175370Z"
    },
    "papermill": {
     "duration": 0.017501,
     "end_time": "2024-07-08T18:23:46.179065",
     "exception": false,
     "start_time": "2024-07-08T18:23:46.161564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default device set to cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "generator = torch.Generator(device=device)\n",
    "print(f\"default device set to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "218a41e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:46.192704Z",
     "iopub.status.busy": "2024-07-08T18:23:46.191788Z",
     "iopub.status.idle": "2024-07-08T18:23:47.814885Z",
     "shell.execute_reply": "2024-07-08T18:23:47.813610Z"
    },
    "papermill": {
     "duration": 1.632321,
     "end_time": "2024-07-08T18:23:47.817191",
     "exception": false,
     "start_time": "2024-07-08T18:23:46.184870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mary</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>7065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Anna</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Emma</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Minnie</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825428</th>\n",
       "      <td>1825429</td>\n",
       "      <td>Zykeem</td>\n",
       "      <td>2014</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825429</th>\n",
       "      <td>1825430</td>\n",
       "      <td>Zymeer</td>\n",
       "      <td>2014</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825430</th>\n",
       "      <td>1825431</td>\n",
       "      <td>Zymiere</td>\n",
       "      <td>2014</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825431</th>\n",
       "      <td>1825432</td>\n",
       "      <td>Zyran</td>\n",
       "      <td>2014</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825432</th>\n",
       "      <td>1825433</td>\n",
       "      <td>Zyrin</td>\n",
       "      <td>2014</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1825433 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id       Name  Year Gender  Count\n",
       "0              1       Mary  1880      F   7065\n",
       "1              2       Anna  1880      F   2604\n",
       "2              3       Emma  1880      F   2003\n",
       "3              4  Elizabeth  1880      F   1939\n",
       "4              5     Minnie  1880      F   1746\n",
       "...          ...        ...   ...    ...    ...\n",
       "1825428  1825429     Zykeem  2014      M      5\n",
       "1825429  1825430     Zymeer  2014      M      5\n",
       "1825430  1825431    Zymiere  2014      M      5\n",
       "1825431  1825432      Zyran  2014      M      5\n",
       "1825432  1825433      Zyrin  2014      M      5\n",
       "\n",
       "[1825433 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_csv = pd.read_csv(\"/kaggle/input/us-baby-names/NationalNames.csv\")\n",
    "names_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19368961",
   "metadata": {
    "papermill": {
     "duration": 0.005832,
     "end_time": "2024-07-08T18:23:47.829455",
     "exception": false,
     "start_time": "2024-07-08T18:23:47.823623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model hyperparameters\n",
    "- context_size --> how many characters the model look at before making a prediction\n",
    "- n_embd --> number of values per character token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650139c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:47.843917Z",
     "iopub.status.busy": "2024-07-08T18:23:47.843026Z",
     "iopub.status.idle": "2024-07-08T18:23:48.298974Z",
     "shell.execute_reply": "2024-07-08T18:23:48.297912Z"
    },
    "papermill": {
     "duration": 0.465857,
     "end_time": "2024-07-08T18:23:48.301378",
     "exception": false,
     "start_time": "2024-07-08T18:23:47.835521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_size = 4\n",
    "n_embd = 5\n",
    "vocab = set(\"\".join(names_csv[\"Name\"]))\n",
    "vocab.add(\".\")\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211b857",
   "metadata": {
    "papermill": {
     "duration": 0.005761,
     "end_time": "2024-07-08T18:23:48.313235",
     "exception": false,
     "start_time": "2024-07-08T18:23:48.307474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e229f910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:48.327338Z",
     "iopub.status.busy": "2024-07-08T18:23:48.326963Z",
     "iopub.status.idle": "2024-07-08T18:23:48.332914Z",
     "shell.execute_reply": "2024-07-08T18:23:48.331920Z"
    },
    "papermill": {
     "duration": 0.016159,
     "end_time": "2024-07-08T18:23:48.335529",
     "exception": false,
     "start_time": "2024-07-08T18:23:48.319370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "w\n"
     ]
    }
   ],
   "source": [
    "stoi = {c: v for v, c in enumerate(vocab)}\n",
    "itos = {v: c for c, v in stoi.items()}\n",
    "print(stoi[\".\"])\n",
    "print(itos[39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdad48e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:48.349498Z",
     "iopub.status.busy": "2024-07-08T18:23:48.349141Z",
     "iopub.status.idle": "2024-07-08T18:23:48.356256Z",
     "shell.execute_reply": "2024-07-08T18:23:48.355143Z"
    },
    "papermill": {
     "duration": 0.016834,
     "end_time": "2024-07-08T18:23:48.358482",
     "exception": false,
     "start_time": "2024-07-08T18:23:48.341648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dataset(data, context_size):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    context = [stoi[\".\"]] * context_size\n",
    "    for name in names_csv[\"Name\"][:10000]:\n",
    "        for ch in name:\n",
    "            inputs.append(context)\n",
    "            labels.append(stoi[ch])\n",
    "            context = context[1:] + [stoi[ch]]\n",
    "    \n",
    "    inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return TensorDataset(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d726a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:48.372373Z",
     "iopub.status.busy": "2024-07-08T18:23:48.372016Z",
     "iopub.status.idle": "2024-07-08T18:23:48.467723Z",
     "shell.execute_reply": "2024-07-08T18:23:48.466827Z"
    },
    "papermill": {
     "duration": 0.105431,
     "end_time": "2024-07-08T18:23:48.470139",
     "exception": false,
     "start_time": "2024-07-08T18:23:48.364708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = make_dataset(data=names_csv, context_size=context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "280d219b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:48.484320Z",
     "iopub.status.busy": "2024-07-08T18:23:48.483937Z",
     "iopub.status.idle": "2024-07-08T18:23:48.504655Z",
     "shell.execute_reply": "2024-07-08T18:23:48.503566Z"
    },
    "papermill": {
     "duration": 0.030722,
     "end_time": "2024-07-08T18:23:48.507116",
     "exception": false,
     "start_time": "2024-07-08T18:23:48.476394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_split = int(len(dataset) * 0.8)\n",
    "test_split = int(len(dataset) - train_split)\n",
    "train_dataset, test_dataset = random_split(dataset=dataset, lengths=[train_split, test_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d42770e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:48.521406Z",
     "iopub.status.busy": "2024-07-08T18:23:48.521034Z",
     "iopub.status.idle": "2024-07-08T18:23:48.526748Z",
     "shell.execute_reply": "2024-07-08T18:23:48.525560Z"
    },
    "papermill": {
     "duration": 0.015908,
     "end_time": "2024-07-08T18:23:48.529157",
     "exception": false,
     "start_time": "2024-07-08T18:23:48.513249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, generator=generator)\n",
    "test_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d6c4c3",
   "metadata": {
    "papermill": {
     "duration": 0.006556,
     "end_time": "2024-07-08T18:23:48.542609",
     "exception": false,
     "start_time": "2024-07-08T18:23:48.536053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc938c40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:48.558568Z",
     "iopub.status.busy": "2024-07-08T18:23:48.558184Z",
     "iopub.status.idle": "2024-07-08T18:23:48.573333Z",
     "shell.execute_reply": "2024-07-08T18:23:48.572128Z"
    },
    "papermill": {
     "duration": 0.026191,
     "end_time": "2024-07-08T18:23:48.575780",
     "exception": false,
     "start_time": "2024-07-08T18:23:48.549589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, context_size, vocab_size, n_embd):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.context_size = context_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        \n",
    "        self.token_emb = nn.Embedding(vocab_size, n_embd) # B x T x C (B=batches; T=context_size, C=n_embd)\n",
    "        self.linear1 = nn.Linear(in_features=context_size*n_embd, out_features=8*8)\n",
    "        self.linear2 = nn.Linear(in_features=8*8, out_features=vocab_size)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.token_emb(x)\n",
    "        \n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T*C)\n",
    "        x = self.act_fn(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def generate_name(self, starting_char, max_length, randomize: bool):\n",
    "        name = \"\"\n",
    "        last_char = starting_char\n",
    "        i = 0\n",
    "        while last_char != \".\" and i < max_length:\n",
    "            context = [stoi[\".\"]] * (self.context_size - 1) + [stoi[last_char]]\n",
    "            context = torch.tensor(context, dtype=torch.long).view(1, len(context))\n",
    "\n",
    "            logits = self(context)\n",
    "            percents = torch.softmax(logits, dim=1)\n",
    "            \n",
    "            if randomize:\n",
    "                pred = torch.multinomial(percents, num_samples=1)\n",
    "            else:\n",
    "                pred = torch.argmax(percents, dim=1)\n",
    "            \n",
    "            i += 1\n",
    "            name += itos[pred.item()]\n",
    "            last_char = itos[pred.item()]\n",
    "        return name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0405c49",
   "metadata": {
    "papermill": {
     "duration": 0.00682,
     "end_time": "2024-07-08T18:23:48.591195",
     "exception": false,
     "start_time": "2024-07-08T18:23:48.584375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define the model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0b491c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:48.607520Z",
     "iopub.status.busy": "2024-07-08T18:23:48.606782Z",
     "iopub.status.idle": "2024-07-08T18:23:50.042510Z",
     "shell.execute_reply": "2024-07-08T18:23:50.040947Z"
    },
    "papermill": {
     "duration": 1.445874,
     "end_time": "2024-07-08T18:23:50.045255",
     "exception": false,
     "start_time": "2024-07-08T18:23:48.599381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MLP(context_size=context_size, vocab_size=vocab_size, n_embd=n_embd)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2112d747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:50.060158Z",
     "iopub.status.busy": "2024-07-08T18:23:50.059282Z",
     "iopub.status.idle": "2024-07-08T18:23:50.144758Z",
     "shell.execute_reply": "2024-07-08T18:23:50.143469Z"
    },
    "papermill": {
     "duration": 0.095816,
     "end_time": "2024-07-08T18:23:50.147332",
     "exception": false,
     "start_time": "2024-07-08T18:23:50.051516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UflOK\n",
      "wwwww\n"
     ]
    }
   ],
   "source": [
    "name_from_distribution = model.generate_name(starting_char=\"L\", max_length=5, randomize=True)\n",
    "name = model.generate_name(starting_char=\"L\", max_length=5, randomize=False)\n",
    "\n",
    "print(name_from_distribution)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b47269",
   "metadata": {
    "papermill": {
     "duration": 0.006007,
     "end_time": "2024-07-08T18:23:50.159662",
     "exception": false,
     "start_time": "2024-07-08T18:23:50.153655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abd0bdfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:50.174127Z",
     "iopub.status.busy": "2024-07-08T18:23:50.173717Z",
     "iopub.status.idle": "2024-07-08T18:23:50.198265Z",
     "shell.execute_reply": "2024-07-08T18:23:50.197097Z"
    },
    "papermill": {
     "duration": 0.034704,
     "end_time": "2024-07-08T18:23:50.200699",
     "exception": false,
     "start_time": "2024-07-08T18:23:50.165995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "E\n"
     ]
    }
   ],
   "source": [
    "# way to generate characters from probability distribution\n",
    "tensor = torch.softmax(torch.randn(size=(1, vocab_size)), dim=1)\n",
    "print(tensor.sum(dim=1))\n",
    "multinomial = torch.multinomial(tensor, num_samples=1)\n",
    "print(itos[multinomial.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f446b662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:50.215693Z",
     "iopub.status.busy": "2024-07-08T18:23:50.214778Z",
     "iopub.status.idle": "2024-07-08T18:23:50.221676Z",
     "shell.execute_reply": "2024-07-08T18:23:50.220540Z"
    },
    "papermill": {
     "duration": 0.016687,
     "end_time": "2024-07-08T18:23:50.223923",
     "exception": false,
     "start_time": "2024-07-08T18:23:50.207236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, loss_fn, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch % 5000 == 0:\n",
    "                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")\n",
    "                \n",
    "    print(f\"loss for the very last batch --> {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bbb8ab",
   "metadata": {
    "papermill": {
     "duration": 0.006057,
     "end_time": "2024-07-08T18:23:50.236437",
     "exception": false,
     "start_time": "2024-07-08T18:23:50.230380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4005ae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:23:50.250655Z",
     "iopub.status.busy": "2024-07-08T18:23:50.250265Z",
     "iopub.status.idle": "2024-07-08T18:23:51.240295Z",
     "shell.execute_reply": "2024-07-08T18:23:51.239148Z"
    },
    "papermill": {
     "duration": 1.000353,
     "end_time": "2024-07-08T18:23:51.243051",
     "exception": false,
     "start_time": "2024-07-08T18:23:50.242698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 0 --> 4.01127815246582 at epoch 0\n",
      "loss for the very last batch --> 3.0978660583496094\n"
     ]
    }
   ],
   "source": [
    "train_model(model=model, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae498f2d",
   "metadata": {
    "papermill": {
     "duration": 0.006574,
     "end_time": "2024-07-08T18:23:51.256150",
     "exception": false,
     "start_time": "2024-07-08T18:23:51.249576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 13,
     "sourceId": 7651,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.234385,
   "end_time": "2024-07-08T18:23:52.385393",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-08T18:23:39.151008",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
